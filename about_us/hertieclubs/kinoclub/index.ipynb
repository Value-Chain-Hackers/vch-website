{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title:  '{{< animate fadeInDown \"Hertie School Kino Club\"delay=.6s >}}'\n",
        "subtitle: '{{< animate fadeInDown \"Kino Club gives students an easy introduction into the craft and power of cinema. From blockbusters to arthouse and from Asia to Europe, Kino Club will host diverse screenings and themed film festivals. \"delay=.6s >}}'\n",
        "categories: [\"Cinema\", \"Films\"]\n",
        "toc: true\n",
        "draft: false\n",
        "code-link: true\n",
        "code-copy: true\n",
        "title-block-banner: true\n",
        "image: images/kino_club.png\n",
        "include-in-header: meta.html\n",
        "comments: false\n",
        "---"
      ],
      "id": "eff2046a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](images/pdf_to_text.png){fig-align=\"center\"}\n",
        "\n",
        "\n",
        "The ability to extract and manipulate data from PDF files is an essential skill for anyone who works with digital documents. For example: organizations, governments, universities, and businesses use themas tools to publish data. Just imagine this: I've often seen governments publish their data in pdfs as tables. As a public policy maker or as a data analyst, that can be painful; imagine translate all that information by hand or using paid tools as PDFTables or Convert from PDF to Excel online. This is where Python and the `pdfplumber` and `tabulate` libraries comes in handy: it allows us to extract text, tables, and other data from PDF files with ease, making it a valuable tool for data analysis and processing. I would also add that this skill is useful as a crucial step for Natural Language Processing since a lot of potential inputs right now are just in pdf texts. \n",
        "\n",
        "In the next lines, I'll show how we can extract text from PDF documents that also includes tables. This approach is easy to understand and reliable, so, anyone can posses and domain this skill; you just need a little bit of knowledge about Python and how we can work with objects.\n",
        "\n",
        "\n",
        "::: callout-warning\n",
        "## Important\n",
        "\n",
        "The next approach applies only to PDF documents that have text inside and are not scanned documents. If you have a pdf document that are scanned text, then Optical character recognition (OCR) algorithms are necessary to realize this task. This method can be implemented in another entry within the Hertie Coding Club.\n",
        ":::\n",
        "\n",
        "\n",
        "Â \n",
        "\n",
        "If you are working within your Python environment, please install this packages. Otherwise, I'll give you the google collab where you can run Python code without installing it in your computer.\n",
        "\n",
        "::: callout-important\n",
        "## Checkout\n",
        "\n",
        "If you are running the code locally, please be sure that you have installed the latest Java version since tabulate works within this framework. `tabulate` library uses Java to render the results.\n",
        ":::\n",
        "\n",
        "\n",
        "## Install packages\n"
      ],
      "id": "0a3b045d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "\n",
        "pip install pdfplumber #Library used to extract text from pdf documents\n",
        "pip install pandas #Library to manipulate dataframes\n",
        "pip install tabula-py tabulate #Library to extract tables from PDF documents. "
      ],
      "id": "e776ac38",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extract data from a PDF document\n",
        "\n",
        "\n",
        "This is the [document](https://www.hertie-school.org/fileadmin/1_Study/11_Scholarships_FinancialAid/US_loans/03_MPP_Study__Examination___Admission_Rules.pdf) that we will use to this example. It's a document from the Hertie School that describes the Study, Examination, and Admission Rules in 2016 for the MPP program. Here our goal will be extract all the content from it and put it in a dataframe. \n"
      ],
      "id": "d876443a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#Import libraries\n",
        "import pdfplumber as pp\n",
        "import pandas as pd\n",
        "\n",
        "#Set PDF file name\n",
        "pdf = 'MPP_Study_Example.pdf'\n",
        "\n",
        "#Open PDF file and extract data from each page\n",
        "with pp.open(pdf) as book:\n",
        "    #Initialize an empty list to store text\n",
        "    page_data = []\n",
        "    #Loop over each page in the PDF file\n",
        "    for page_no, page in enumerate(book.pages, start = 1):\n",
        "        #Extract text from page\n",
        "        data = page.extract_text()\n",
        "        #Append page data to list\n",
        "        page_data.append([pdf, data.strip(), page_no])\n",
        "\n",
        "#Create pandas DataFrame from page data and set column names\n",
        "df_text = pd.DataFrame(page_data, columns=['file_name', 'text', 'page_number'])\n",
        "\n",
        "#Display DataFrame\n",
        "print(df_text)\n"
      ],
      "id": "87c659c1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We have three columns. The first one shows the document's name where we extracted the text. The second column contains the text, and the third one the number of pages. Of course, you can modify the code and the variable names according to your necessities. \n",
        "\n",
        "\n",
        "If you want to save your dataframe, remember this functions:\n"
      ],
      "id": "9a1a786b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "\n",
        "# Save the dataframe to a CSV file\n",
        "df_text.to_csv('df_text_pdf.csv', index=False)\n",
        "\n",
        "# Save the dataframe to an Excel file\n",
        "df_text.to_excel('df_text_pdf.xlsx', index=False)"
      ],
      "id": "25366de3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you look close, there is a table in page number 5. `PDFplumber` renders that as text and not in a table format. One approach to this would be use now the `tabulate` library to extract exclsuively tables from our document. The table inside the document is not clear or doesn't have a completely table format. However, we can still apply our function to extract that table and approach it to a nice table format. \n"
      ],
      "id": "0127e925"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#Import required libraries\n",
        "import tabula\n",
        "import numpy as np\n",
        "from tabula import read_pdf\n",
        "from tabulate import tabulate\n",
        "\n",
        "#Set the path to the PDF file\n",
        "pdf_path = 'MPP_Study_Example.pdf'\n",
        "\n",
        "#Read all tables from the PDF file into a list of DataFrames\n",
        "df_list = tabula.read_pdf(pdf_path, pages=\"all\", multiple_tables=True)\n",
        "\n",
        "#Print the list of DataFrames\n",
        "print(df_list)\n"
      ],
      "id": "a885063f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As you can see, we have a list with three dataframes. Our library recognized 3 tables, however, there is just really one at page 5. Now let's just keep with the one that matter to us. \n"
      ],
      "id": "0f618f47"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(df_list[1])"
      ],
      "id": "6449d7a0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here is our table or interest. Let's do some wrangling to clean it. \n"
      ],
      "id": "abb28fc3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| warning: false\n",
        "\n",
        "\n",
        "#Extract the second table from the list and skip the header row\n",
        "df_table = df_list[1].iloc[1:]\n",
        "\n",
        "#Replace commas with dots and convert to numeric values\n",
        "df_table[\"German\"] = pd.to_numeric(df_table[\"German\"].str.replace(',', '.'), \n",
        "                                                              errors='coerce')\n",
        "\n",
        "#Rename columns\n",
        "df_table = df_table.rename(columns={'German': 'Grade', 'Numerical': 'Percentage'})\n",
        "\n",
        "#Define a function to map grades to categories. We are doing this\n",
        "#since if we use a statement, our code will be larger.\n",
        "def grade(score):\n",
        "    if score >= 1 and score <= 1.3:\n",
        "        return 'excellent'\n",
        "    elif score > 1.3 and score <= 2:\n",
        "        return 'very good'\n",
        "    elif score > 2 and score <= 2.7:\n",
        "        return 'good'\n",
        "    elif score > 2.7 and score <= 3.3:\n",
        "        return 'satisfactory'\n",
        "    elif score > 3.3 and score < 4:\n",
        "        return 'sufficient'\n",
        "    elif score >= 4:\n",
        "        return 'fail'\n",
        "    else:\n",
        "        return np.nan\n",
        "\n",
        "#Apply the grade function to create a new column with grade categories\n",
        "df_table['Grade Category'] = df_table['Grade'].apply(grade)\n",
        "\n",
        "#Drop rows with missing grade categories\n",
        "df_table = df_table.dropna(subset=['Grade Category'])\n",
        "\n",
        "#Drop the \"Definition\" column\n",
        "df_table = df_table.drop('Definition', axis=1)\n",
        "\n",
        "#Extract minimum and maximum percentage values to replace the Percentage. \n",
        "#Here we use some regex to obtain just the numbers within a \"-\"\n",
        "df_table[['Min%', 'Max%']] = df_table['Percentage'].str.extract(r'(\\d+)-(\\d+)%')\n",
        "\n",
        "#Convert percentage values to float\n",
        "df_table[['Min%', 'Max%']] = df_table[['Min%', 'Max%']].astype(float) / 100\n",
        "\n",
        "#Drop the original \"Percentage\" column\n",
        "df_table_final = df_table.drop('Percentage', axis = 1)\n",
        "\n",
        "#Print the final table\n",
        "print(df_table_final)\n"
      ],
      "id": "99e8c7f7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.callout-note}\n",
        "## Remember\n",
        "\n",
        "To save a dataframe or your table, use this functions:\n"
      ],
      "id": "294249c3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "\n",
        "# Save the dataframe to a CSV file\n",
        "df_table_final.to_csv('df_text_pdf.csv', index=False)\n",
        "\n",
        "# Save the dataframe to an Excel file\n",
        "df_table_final.to_excel('df_text_pdf.xlsx', index=False)"
      ],
      "id": "fa3014c1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        "Â \n",
        "\n",
        "## Extract tables from a PDF document\n",
        "\n",
        "\n",
        "As you can see, the last example was just a form to deal with a tabl when we don't have a clear pattern of it in a document. Generally, we need another tool to extract a table from a document since it will be much easier because of the `tabula` library it's trained just to recognize tables. Now, we will use another document with cleaner tables, and the library can work even better. We will use a [document](https://sedl.org/afterschool/toolkits/science/pdf/ast_sci_data_tables_sample.pdf) that contains text but also much cleaner tables. \n"
      ],
      "id": "d85b6973"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import tabula\n",
        "from tabula import read_pdf\n",
        "from tabulate import tabulate\n",
        "\n",
        "df_list_example2 = tabula.read_pdf('ast_sci_data_tables_sample.pdf', \n",
        "                                    pages=\"all\", multiple_tables = True)\n",
        "\n",
        "#We use len to determine how many tables the document has\n",
        "len(df_list_example2)"
      ],
      "id": "a13994bc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We have for tables. Let's see them closer:\n"
      ],
      "id": "78833978"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(df_list_example2)"
      ],
      "id": "21ce2b8b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Looks good! Let's say that I just want the second table, so, I use the index of the list to keep with my dataframe.\n"
      ],
      "id": "311f145e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(df_list_example2[1])"
      ],
      "id": "b9328ebf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusion \n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "Now, we can use this for our own purposes. Asou can see, the process was much straight forward. In conclusion, this is just one approach of multiple ones since there are different libraries depending of what you want to do. However, I like this libraries since are easy to understand. Finally, if you want to reproduce this code, here I leave a Google Colab notebook for you to input your pdf's and get the text out of it. This step is super interesting and I would say necessary to start a pipeline for NLP models, analysis of text, etc. \n",
        "\n",
        "\n",
        "Â \n",
        "\n",
        "<div style=\"text-align:center;\">\n",
        "[<img src=\"https://colab.research.google.com/assets/colab-badge.svg\" width=\"250\">](https://colab.research.google.com/drive/1qBVCIpBReACYi1Pi81bOWZNw66XsY2mA?usp=sharing)\n",
        "</div>\n",
        "\n",
        "Â \n",
        "Â \n",
        "\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "::: callout-note\n",
        "## Reference\n",
        "Cite this page: Roa, J. (2023, April 18). *PDF to text*. Hertie Coding Club. [URL](https://www.hertiecodingclub.com/learn/python/pdf_to_text/)\n",
        ":::\n"
      ],
      "id": "0f74b2fa"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}