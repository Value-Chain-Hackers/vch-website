[
  {
    "objectID": "members.html",
    "href": "members.html",
    "title": "Members",
    "section": "",
    "text": "About this site\n\n\n\n\n# Load the ggplot2 package\nlibrary(ggplot2)\n\n\n# Create some example data\nx <- 1:10\ny <- x^2\n\n# Create the plot\nggplot(data = data.frame(x, y), aes(x = x, y = y)) +\n  geom_line() + theme(text = element_text(family = \"Arial\", size = 20))\n\n\n\n\n\n\n\n\nWho are we?\n\nWhen the moon hits your eye\n\n\n damoncroberts\n DamonCharlesRoberts\n Wednesdays from 12:15 - 2:15 pm Mountain\n Ketchum Arts & Sciences, Office 382, Boulder, CO 80309\nSome text"
  },
  {
    "objectID": "learn/python/pdf_to_text/index.html",
    "href": "learn/python/pdf_to_text/index.html",
    "title": "PDF to text",
    "section": "",
    "text": "The ability to extract and manipulate data from PDF files is an essential skill for anyone who works with digital documents. For example: organizations, governments, universities, and businesses use themas tools to publish data. Just imagine this: I’ve often seen governments publish their data in pdfs as tables. As a public policy maker or as a data analyst, that can be painful; imagine translate all that information by hand or using paid tools as PDFTables or Convert from PDF to Excel online. This is where Python and the pdfplumber and tabulate libraries comes in handy: it allows us to extract text, tables, and other data from PDF files with ease, making it a valuable tool for data analysis and processing. I would also add that this skill is useful as a crucial step for Natural Language Processing since a lot of potential inputs right now are just in pdf texts.\nIn the next lines, I’ll show how we can extract text from PDF documents that also includes tables. This approach is easy to understand and reliable, so, anyone can posses and domain this skill; you just need a little bit of knowledge about Python and how we can work with objects.\nIf you are working within your Python environment, please install this packages. Otherwise, I’ll give you the google collab where you can run Python code without installing it in your computer."
  },
  {
    "objectID": "learn/python/pdf_to_text/index.html#install-packages",
    "href": "learn/python/pdf_to_text/index.html#install-packages",
    "title": "PDF to text",
    "section": "Install packages",
    "text": "Install packages\n\npip install pdfplumber #Library used to extract text from pdf documents\npip install pandas #Library to manipulate dataframes\npip install tabula-py tabulate #Library to extract tables from PDF documents."
  },
  {
    "objectID": "learn/python/pdf_to_text/index.html#extract-data-from-a-pdf-document",
    "href": "learn/python/pdf_to_text/index.html#extract-data-from-a-pdf-document",
    "title": "PDF to text",
    "section": "Extract data from a PDF document",
    "text": "Extract data from a PDF document\nThis is the document that we will use to this example. It’s a document from the Hertie School that describes the Study, Examination, and Admission Rules in 2016 for the MPP program. Here our goal will be extract all the content from it and put it in a dataframe.\n\n#Import libraries\nimport pdfplumber as pp\nimport pandas as pd\n\n#Set PDF file name\npdf = 'MPP_Study_Example.pdf'\n\n#Open PDF file and extract data from each page\nwith pp.open(pdf) as book:\n    #Initialize an empty list to store text\n    page_data = []\n    #Loop over each page in the PDF file\n    for page_no, page in enumerate(book.pages, start = 1):\n        #Extract text from page\n        data = page.extract_text()\n        #Append page data to list\n        page_data.append([pdf, data.strip(), page_no])\n\n#Create pandas DataFrame from page data and set column names\ndf_text = pd.DataFrame(page_data, columns=['file_name', 'text', 'page_number'])\n\n#Display DataFrame\nprint(df_text)\n\n               file_name                                               text   \n0  MPP_Study_Example.pdf  Master of Public Policy\\nStudy, Examination, a...  \\\n1  MPP_Study_Example.pdf  I. Study Rules\\n§ 1 Object\\nThese study rules ...   \n2  MPP_Study_Example.pdf  (3) Advanced Curriculum\\nIn the second year of...   \n3  MPP_Study_Example.pdf  § 6 Examination Committee\\n(1) An Examination ...   \n4  MPP_Study_Example.pdf  (4) Upon written request, the Examination Comm...   \n5  MPP_Study_Example.pdf  (5) Students can request to be ranked in relat...   \n6  MPP_Study_Example.pdf  (2) In addition to the degree certificate, stu...   \n7  MPP_Study_Example.pdf  (2) If the Examination Committee comes to the ...   \n8  MPP_Study_Example.pdf  2. a high level of proficiency in written and ...   \n\n   page_number  \n0            1  \n1            2  \n2            3  \n3            4  \n4            5  \n5            6  \n6            7  \n7            8  \n8            9  \n\n\nWe have three columns. The first one shows the document’s name where we extracted the text. The second column contains the text, and the third one the number of pages. Of course, you can modify the code and the variable names according to your necessities.\nIf you want to save your dataframe, remember this functions:\n\n# Save the dataframe to a CSV file\ndf_text.to_csv('df_text_pdf.csv', index=False)\n\n# Save the dataframe to an Excel file\ndf_text.to_excel('df_text_pdf.xlsx', index=False)\n\nIf you look close, there is a table in page number 5. PDFplumber renders that as text and not in a table format. One approach to this would be use now the tabulate library to extract exclsuively tables from our document. The table inside the document is not clear or doesn’t have a completely table format. However, we can still apply our function to extract that table and approach it to a nice table format.\n\n#Import required libraries\nimport tabula\nimport numpy as np\nfrom tabula import read_pdf\nfrom tabulate import tabulate\n\n#Set the path to the PDF file\npdf_path = 'MPP_Study_Example.pdf'\n\n#Read all tables from the PDF file into a list of DataFrames\ndf_list = tabula.read_pdf(pdf_path, pages=\"all\", multiple_tables=True)\n\n#Print the list of DataFrames\nprint(df_list)\n\n[    (2)   \n0   NaN  \\\n1   (3)   \n2   NaN   \n3   NaN   \n4   NaN   \n5   NaN   \n6   (4)   \n7   NaN   \n8   NaN   \n9   (5)   \n10  NaN   \n11  (6)   \n12  NaN   \n13  NaN   \n14  NaN   \n15  (7)   \n16  NaN   \n17  NaN   \n18  (8)   \n\n   The Academic Senate of the Hertie School of Governance elects the faculty members for a  \n0   two-year term and the student representative f...                                       \n1   The Examination Committee meets in camera and ...                                       \n2   the Committee are obliged to maintain secrecy ...                                       \n3   them in their capacity as members of the Commi...                                       \n4   individual students. The members shall also no...                                       \n5                                                end.                                       \n6   The Examination Committee is responsible for t...                                       \n7   shall ensure the timely fulfilment of the regu...                                       \n8                                           involved.                                       \n9   The Examination Committee makes and accepts su...                                       \n10                             the Examination Rules.                                       \n11  Credits earned by a student at another univers...                                       \n12  Examination Committee. The Committee shall app...                                       \n13  regard to study contents, learning objectives,...                                       \n14                           examination requirement.                                       \n15  A student’s professional experience shall be r...                                       \n16  Examination Committee. The Committee shall app...                                       \n17  relevant in respect to contents and learning o...                                       \n18  The Examination Committee shall decide in all ...                                       ,    German Numerical Alphanumeric    Definition\n0   Grade     Grade        Grade           NaN\n1     1,0   100-96%           A+           NaN\n2     NaN       NaN          NaN     excellent\n3     1,3    95-91%            A           NaN\n4     1,7    90-86%           A-           NaN\n5     NaN       NaN          NaN     very good\n6     2,0    85-81%           B+           NaN\n7     2,3    80-76%            B           NaN\n8     NaN       NaN          NaN          good\n9     2,7    75-71%            B           NaN\n10    3,0    70-66%           B-           NaN\n11    NaN       NaN          NaN  satisfactory\n12    3,3    65-61%           C+           NaN\n13    3,7    60-56%            C           NaN\n14    NaN       NaN          NaN    sufficient\n15    4,0    55-50%           C-           NaN\n16    5,0     49-0%            F          fail,    (2) A failed requirement can be repeated twice only if it leads to a failed examination (i.e. if the\n0   weighted average grade of all requirements is ...                                                  \n1   The student shall be given one opportunity to ...                                                  \n2                         of the subsequent semester.                                                  \n3   (3) For the last repetition of an examination ...                                                  \n4                                appoint two graders.                                                  \n5   (4) The regulations concerning the master thes...                                                  \n6                                  § 11 Master Thesis                                                  \n7   (1) Students submit their master thesis to the...                                                  \n8   The submission date shall be determined for ea...                                                  \n9                                          Committee.                                                  \n10  (2) The master thesis shall be supervised by a...                                                  \n11  the Examination Committee can appoint a member...                                                  \n12                                        supervisor.                                                  \n13  (3) The written master thesis is graded by the...                                                  \n14  thesis supervisor and one member of the core f...                                                  \n15  thesis is constituted by the arithmetic mean o...                                                  \n16                                  Thesis Committee.                                                  \n17  (4) Students who fail their written master the...                                                  ,    (1)   \n0  NaN  \\\n1  NaN   \n2  (2)   \n\n  The Admissions Committee decides on admissions in accordance with the guidelines laid  \n0  down by the Dean as well as on the basis of mo...                                     \n1                                         Committee.                                     \n2  The Committee consists of at least six members...                                     ]\n\n\nAs you can see, we have a list with three dataframes. Our library recognized 3 tables, however, there is just really one at page 5. Now let’s just keep with the one that matter to us.\n\nprint(df_list[1])\n\n   German Numerical Alphanumeric    Definition\n0   Grade     Grade        Grade           NaN\n1     1,0   100-96%           A+           NaN\n2     NaN       NaN          NaN     excellent\n3     1,3    95-91%            A           NaN\n4     1,7    90-86%           A-           NaN\n5     NaN       NaN          NaN     very good\n6     2,0    85-81%           B+           NaN\n7     2,3    80-76%            B           NaN\n8     NaN       NaN          NaN          good\n9     2,7    75-71%            B           NaN\n10    3,0    70-66%           B-           NaN\n11    NaN       NaN          NaN  satisfactory\n12    3,3    65-61%           C+           NaN\n13    3,7    60-56%            C           NaN\n14    NaN       NaN          NaN    sufficient\n15    4,0    55-50%           C-           NaN\n16    5,0     49-0%            F          fail\n\n\nHere is our table or interest. Let’s do some wrangling to clean it.\n\n#Extract the second table from the list and skip the header row\ndf_table = df_list[1].iloc[1:]\n\n#Replace commas with dots and convert to numeric values\ndf_table[\"German\"] = pd.to_numeric(df_table[\"German\"].str.replace(',', '.'), \n                                                              errors='coerce')\n\n#Rename columns\ndf_table = df_table.rename(columns={'German': 'Grade', 'Numerical': 'Percentage'})\n\n#Define a function to map grades to categories. We are doing this\n#since if we use a statement, our code will be larger.\ndef grade(score):\n    if score >= 1 and score <= 1.3:\n        return 'excellent'\n    elif score > 1.3 and score <= 2:\n        return 'very good'\n    elif score > 2 and score <= 2.7:\n        return 'good'\n    elif score > 2.7 and score <= 3.3:\n        return 'satisfactory'\n    elif score > 3.3 and score < 4:\n        return 'sufficient'\n    elif score >= 4:\n        return 'fail'\n    else:\n        return np.nan\n\n#Apply the grade function to create a new column with grade categories\ndf_table['Grade Category'] = df_table['Grade'].apply(grade)\n\n#Drop rows with missing grade categories\ndf_table = df_table.dropna(subset=['Grade Category'])\n\n#Drop the \"Definition\" column\ndf_table = df_table.drop('Definition', axis=1)\n\n#Extract minimum and maximum percentage values to replace the Percentage. \n#Here we use some regex to obtain just the numbers within a \"-\"\ndf_table[['Min%', 'Max%']] = df_table['Percentage'].str.extract(r'(\\d+)-(\\d+)%')\n\n#Convert percentage values to float\ndf_table[['Min%', 'Max%']] = df_table[['Min%', 'Max%']].astype(float) / 100\n\n#Drop the original \"Percentage\" column\ndf_table_final = df_table.drop('Percentage', axis = 1)\n\n#Print the final table\nprint(df_table_final)\n\n    Grade Alphanumeric Grade Category  Min%  Max%\n1     1.0           A+      excellent  1.00  0.96\n3     1.3            A      excellent  0.95  0.91\n4     1.7           A-      very good  0.90  0.86\n6     2.0           B+      very good  0.85  0.81\n7     2.3            B           good  0.80  0.76\n9     2.7            B           good  0.75  0.71\n10    3.0           B-   satisfactory  0.70  0.66\n12    3.3           C+   satisfactory  0.65  0.61\n13    3.7            C     sufficient  0.60  0.56\n15    4.0           C-           fail  0.55  0.50\n16    5.0            F           fail  0.49  0.00\n\n\n\n\n\n\n\n\nRemember\n\n\n\nTo save a dataframe or your table, use this functions:\n\n# Save the dataframe to a CSV file\ndf_table_final.to_csv('df_text_pdf.csv', index=False)\n\n# Save the dataframe to an Excel file\ndf_table_final.to_excel('df_text_pdf.xlsx', index=False)"
  },
  {
    "objectID": "learn/python/pdf_to_text/index.html#extract-tables-from-a-pdf-document",
    "href": "learn/python/pdf_to_text/index.html#extract-tables-from-a-pdf-document",
    "title": "PDF to text",
    "section": "Extract tables from a PDF document",
    "text": "Extract tables from a PDF document\nAs you can see, the last example was just a form to deal with a tabl when we don’t have a clear pattern of it in a document. Generally, we need another tool to extract a table from a document since it will be much easier because of the tabula library it’s trained just to recognize tables. Now, we will use another document with cleaner tables, and the library can work even better. We will use a document that contains text but also much cleaner tables.\n\nimport tabula\nfrom tabula import read_pdf\nfrom tabulate import tabulate\n\ndf_list_example2 = tabula.read_pdf('ast_sci_data_tables_sample.pdf', \n                                    pages=\"all\", multiple_tables = True)\n\n#We use len to determine how many tables the document has\nlen(df_list_example2)\n\n3\n\n\nWe have for tables. Let’s see them closer:\n\nprint(df_list_example2)\n\n[   Number of Coils Number of Paperclips\n0                5              3, 5, 4\n1               10              7, 8, 6\n2               15           11, 10, 12\n3               20           15, 13, 14,     Speed (mph)           Driver                         Car     Engine   \n0       407.447  Craig Breedlove           Spirit of America     GE J47  \\\n1       413.199        Tom Green            Wingfoot Express     WE J46   \n2       434.220       Art Arfons               Green Monster     GE J79   \n3       468.719  Craig Breedlove           Spirit of America     GE J79   \n4       526.277  Craig Breedlove           Spirit of America     GE J79   \n5       536.712       Art Arfons               Green Monster     GE J79   \n6       555.127  Craig Breedlove  Spirit of America, Sonic 1     GE J79   \n7       576.553       Art Arfons               Green Monster     GE J79   \n8       600.601  Craig Breedlove  Spirit of America, Sonic 1     GE J79   \n9       622.407    Gary Gabelich                  Blue Flame     Rocket   \n10      633.468    Richard Noble                    Thrust 2  RR RG 146   \n11      763.035       Andy Green                  Thrust SSC    RR Spey   \n\n        Date  \n0     8/5/63  \n1    10/2/64  \n2    10/5/64  \n3   10/13/64  \n4   10/15/65  \n5   10/27/65  \n6    11/2/65  \n7    11/7/65  \n8   11/15/65  \n9   10/23/70  \n10   10/4/83  \n11  10/15/97  ,    Time (drops of water)  Distance (cm)\n0                      1        10,11,9\n1                      2     29, 31, 30\n2                      3     59, 58, 61\n3                      4   102, 100, 98\n4                      5  122, 125, 127]\n\n\nLooks good! Let’s say that I just want the second table, so, I use the index of the list to keep with my dataframe.\n\nprint(df_list_example2[1])\n\n    Speed (mph)           Driver                         Car     Engine   \n0       407.447  Craig Breedlove           Spirit of America     GE J47  \\\n1       413.199        Tom Green            Wingfoot Express     WE J46   \n2       434.220       Art Arfons               Green Monster     GE J79   \n3       468.719  Craig Breedlove           Spirit of America     GE J79   \n4       526.277  Craig Breedlove           Spirit of America     GE J79   \n5       536.712       Art Arfons               Green Monster     GE J79   \n6       555.127  Craig Breedlove  Spirit of America, Sonic 1     GE J79   \n7       576.553       Art Arfons               Green Monster     GE J79   \n8       600.601  Craig Breedlove  Spirit of America, Sonic 1     GE J79   \n9       622.407    Gary Gabelich                  Blue Flame     Rocket   \n10      633.468    Richard Noble                    Thrust 2  RR RG 146   \n11      763.035       Andy Green                  Thrust SSC    RR Spey   \n\n        Date  \n0     8/5/63  \n1    10/2/64  \n2    10/5/64  \n3   10/13/64  \n4   10/15/65  \n5   10/27/65  \n6    11/2/65  \n7    11/7/65  \n8   11/15/65  \n9   10/23/70  \n10   10/4/83  \n11  10/15/97"
  },
  {
    "objectID": "learn/rstudio/rstudio101/index.html",
    "href": "learn/rstudio/rstudio101/index.html",
    "title": "RStudio 101",
    "section": "",
    "text": "This is the window that appears to us when we open R. As you can see, there are multiple things that we will check. But, first we are going to create our first project."
  },
  {
    "objectID": "learn/rstudio/rstudio101/index.html#step-1-opening-a-new-project",
    "href": "learn/rstudio/rstudio101/index.html#step-1-opening-a-new-project",
    "title": "RStudio 101",
    "section": "Step 1: Opening a new project",
    "text": "Step 1: Opening a new project\n\n\n\n\n\nWe will go to File tab and click in “New Project”.\n\n\n\n1.-Create Project\n2.-Project Type\n\n\n\n\n\n\n\nHere you have three options: since you are creating a new project, choose New Directory.\nSelect the type of project, as you can see, we have different options; or now, we will choose New Project"
  },
  {
    "objectID": "learn/rstudio/rstudio101/index.html#step-2-create-our-first-project",
    "href": "learn/rstudio/rstudio101/index.html#step-2-create-our-first-project",
    "title": "RStudio 101",
    "section": "Step 2: Create our first project",
    "text": "Step 2: Create our first project\n\nOnce we open a new project, we need to decide where we want to store our project and all the code we will generate. I’ll talk about this later, but putting a project in a separate folder is good practice to have everything ordered.\n\n\n\n\n\nYour name project should be precise and not too long. In our case, we will name it “Hertie Coding Club R”\n\n\n3.-Choose folder\n4.-Icon project in project folder\n\n\n\n\n\n\n\nHere we show the folder in where we will save our project\nOnce you created your project, it should appear an icon like this within your folder."
  },
  {
    "objectID": "learn/rstudio/rstudio101/index.html#benefits",
    "href": "learn/rstudio/rstudio101/index.html#benefits",
    "title": "RStudio 101",
    "section": "Benefits",
    "text": "Benefits\n\n\n\n\n\n\nBenefits\n\n\n\n\nSetting the working directory wd() makes it easier to read and write files in your R script.\nWhen you set the working directory to the folder where your data files are stored, you can simply specify the file names without having to write out the full file path.\nThis makes your code more readable and easier to maintain.\nSetting the working directory can make it easier to share your code with others since they would load the code from the project folder.\n\n\n\n\n\n\n\n\n\nWhat happens if I don’t create a folder for my project?\n\n\n\n\nIf you do not appropriately set the working directory, R may look for files in the wrong location, which can lead to errors and a lot of time wasted"
  },
  {
    "objectID": "learn/rstudio/rstudio101/index.html#create-a-script",
    "href": "learn/rstudio/rstudio101/index.html#create-a-script",
    "title": "RStudio 101",
    "section": "Create a script",
    "text": "Create a script\nWe will create our first R Script. For that please go to Fil -> New File -> R Script\n\n\n\n\nOnce we create our script, it will show us a window with a tab called “Untitled1”. Now, we need to save that script in our analysis folder. For that, we need to go to File -> Save As. Next, we need to select the folder within our project where we want to save our script. Following the good practices recommended here, I’ll keep it in my analysis folder. I’m naming my script as “first_script”.\n\n\nFile -> R Script"
  },
  {
    "objectID": "learn/rstudio/rstudio101/index.html#source",
    "href": "learn/rstudio/rstudio101/index.html#source",
    "title": "RStudio 101",
    "section": "Source",
    "text": "Source\n\n\n\n\nThe source pane is the main workspace for creating and editing R scripts, and it provides features for syntax highlighting, code completion, and error checking.\n\nOne of the key features of the source pane is syntax highlighting, which makes it easier to read and understand R code by using different colors and fonts to differentiate between different elements of the code, such as keywords, comments, and functions.\n\nWith this commands, you can select your code and run your code.\n\n\n\n\n\n\n“Command + Return\n“Control + Enter”\n\n\nThis code will excute and it will be showed in the console."
  },
  {
    "objectID": "learn/rstudio/rstudio101/index.html#console",
    "href": "learn/rstudio/rstudio101/index.html#console",
    "title": "RStudio 101",
    "section": "Console",
    "text": "Console\nWhen a user types in a command in the console, like for example assigning a variable or running a function, R processes the command and generates the output, which is displayed in the console. The console is a critical tool for debugging R code, as it allows users to see the output of their commands and to identify errors and bugs in their code. In summary:\n\nThe console is the heart of R.\nHere R actually evaluates your code.\nTry to write most of your code in a document in the Source. Only type directly into the Console to de-bug or do quick analyses.\nWhen ready: > and If waiting: +\nCancel commands by pressing Esc. to finish a running process.\n\n\n\n\n\n\n\n\n\nIn the last pictures, for example, we evaluated the expression\n\n2 + 2\n\n[1] 4\n\n\nAs you can see, in our console it shows the operation that we ran. (Remember the commands to run your code). One of the shortcuts that I use often is the ↑ key. Pressing the top arrow shows the last code that you executed; pretty useful if you don’t want to rerun your code"
  },
  {
    "objectID": "learn/rstudio/rstudio101/index.html#environmenthistory",
    "href": "learn/rstudio/rstudio101/index.html#environmenthistory",
    "title": "RStudio 101",
    "section": "Environment/History",
    "text": "Environment/History\nIn R, the environment refers to the collection of variables and their values that are currently stored in the memory. Each time a user creates a variable or loads data into R, those variables and data are stored in the environment. One of the things that I like about using RStudio as a IDE is practically this nice way of putting all the varaibles, data functions and every object that you are loading in your environment. In summary, the environment can be thought of as a workspace where the user can manipulate and analyze the data.\nThe Environment tab of this panel shows you the names of all the objects that you have been creating. For example, you can see information like the number of observations and rows in data objects; lists, funtions, etc."
  },
  {
    "objectID": "learn/rstudio/rstudio101/index.html#files-and-more",
    "href": "learn/rstudio/rstudio101/index.html#files-and-more",
    "title": "RStudio 101",
    "section": "Files and more",
    "text": "Files and more\nIn R, files and directories helps you managing data, plots and code. This pane provides access to the files and directories on the user’s computer. If you can see close, it will show your current working directory; this helps you to check if you are working in the correct directory. Users can navigate through the file system, create new files and directories, and open or delete existing files. The pane also provides features for searching and filtering files, as well as organizing them into projects. I personally use it to preview plots, install packages and check documentation."
  },
  {
    "objectID": "learn/rstudio/Multithreading/index.html",
    "href": "learn/rstudio/Multithreading/index.html",
    "title": "Enable Multithread with data.table in Mac/Intel chips",
    "section": "",
    "text": "This document shows you how we can enable the use of multiple cores on Macs with Intel/Apple silicon chips (M1 and M2).\nIf we load data.table library in  studio, this message will appear in your console:\nAs you can see, OpenMP support is needed to use multiple cores in Macs. Therefore, we must install those packages through the terminal and set the required paths to run OpenMP."
  },
  {
    "objectID": "learn/rstudio/Multithreading/index.html#install-llvm",
    "href": "learn/rstudio/Multithreading/index.html#install-llvm",
    "title": "Enable Multithread with data.table in Mac/Intel chips",
    "section": "Install llvm",
    "text": "Install llvm\nWe need to install the llvm package to access the clang compiler, which helps us to set multithreading.\n\nbrew install llvm\n\n\n\n\n \n\n\n\n\n\n\n\n\nOnce the installation is finished, we should see this screen in the terminal."
  },
  {
    "objectID": "learn/rstudio/Multithreading/index.html#install-libopenmp",
    "href": "learn/rstudio/Multithreading/index.html#install-libopenmp",
    "title": "Enable Multithread with data.table in Mac/Intel chips",
    "section": "Install libopenmp",
    "text": "Install libopenmp\n\nbrew install libopenmp\n\nThis is the screen that you should see once the installation is done."
  },
  {
    "objectID": "learn/rstudio/Multithreading/index.html#install-libopenmpt",
    "href": "learn/rstudio/Multithreading/index.html#install-libopenmpt",
    "title": "Enable Multithread with data.table in Mac/Intel chips",
    "section": "Install libopenmpt",
    "text": "Install libopenmpt\n\nbrew install libopenmpt\n\nThis is the screen that you should see once the installation is done.\n :::"
  },
  {
    "objectID": "learn/rstudio/Multithreading/index.html#install-gcc",
    "href": "learn/rstudio/Multithreading/index.html#install-gcc",
    "title": "Enable Multithread with data.table in Mac/Intel chips",
    "section": "Install gcc",
    "text": "Install gcc\n\nbrew install gcc\n\nThis is the screen that you should see once the installation is done."
  },
  {
    "objectID": "learn/rstudio/Multithreading/index.html#install-cask-openmtp",
    "href": "learn/rstudio/Multithreading/index.html#install-cask-openmtp",
    "title": "Enable Multithread with data.table in Mac/Intel chips",
    "section": "Install –cask openmtp",
    "text": "Install –cask openmtp\n\nbrew install --cask openmtp\n\nThis is the screen that you should see once the installation is done.\n}"
  },
  {
    "objectID": "learn/rstudio/Multithreading/index.html#apple-silicon",
    "href": "learn/rstudio/Multithreading/index.html#apple-silicon",
    "title": "Enable Multithread with data.table in Mac/Intel chips",
    "section": "Apple Silicon",
    "text": "Apple Silicon\n\nHOMEBREW_LOC=/opt/homebrew \nLLVM_LOC=$(HOMEBREW_LOC)/opt/llvm \nCC=$(LLVM_LOC)/bin/clang -fopenmp \nCXX=$(LLVM_LOC)/bin/clang++ -fopenmp \nCFLAGS=-g -O3 -Wall -pedantic -std=gnu99 -mtune=native -pipe \nCXXFLAGS=-g -O3 -Wall -pedantic -std=c++11 -mtune=native -pipe \nLDFLAGS=-L$(HOMEBREW_LOC)/opt/gettext/lib -L$(LLVM_LOC)/lib -Wl,-rpath,$(LLVM_LOC)/lib \nCPPFLAGS=-I$(HOMEBREW_LOC)/opt/gettext/include -I$(LLVM_LOC)/include"
  },
  {
    "objectID": "learn/rstudio/Multithreading/index.html#intel",
    "href": "learn/rstudio/Multithreading/index.html#intel",
    "title": "Enable Multithread with data.table in Mac/Intel chips",
    "section": "Intel",
    "text": "Intel\n\nHOMEBREW_LOC=/usr/local\nLLVM_LOC=$(HOMEBREW_LOC)/opt/llvm\nCC=$(LLVM_LOC)/bin/clang -fopenmp \nCXX=$(LLVM_LOC)/bin/clang++ -fopenmp \nCFLAGS=-g -O3 -Wall -pedantic -std=gnu99 -mtune=native -pipe \nCXXFLAGS=-g -O3 -Wall -pedantic -std=c++11 -mtune=native -pipe \nLDFLAGS=-L$(HOMEBREW_LOC)/opt/gettext/lib -L$(LLVM_LOC)/lib -Wl,-rpath,$(LLVM_LOC)/lib \nCPPFLAGS=-I$(HOMEBREW_LOC)/opt/gettext/include -I$(LLVM_LOC)/include\n\n\n\n\n\nOnce you put the paths, save the text file and close it. The difference between Apple Silicon and Intel is just the path; everything else remains similar. For Apple Silicon, the path is /opt/homebrew and for Intel is /usr/local."
  },
  {
    "objectID": "learn/rstudio/objects/index.html",
    "href": "learn/rstudio/objects/index.html",
    "title": "Understanding R Objects: Naming, Data Structures and Classes in R",
    "section": "",
    "text": "One of the things that define R as an amazing tool to do multiple things are objects. R work with objects that essentialy are data structures that can hold values, but also othr types of data and can be assigned names for easy reference. Objects in R are useful because we can organize and store data in meaningful ways. One of the most importants thigns when you are learning R is understand how to work with these objects because you will have the confidence and knowledge to use it at your better convenience. There are several types of objects in R, including vectors, matrices, data frames, lists, and factors, each with their own characteristics and uses.\n\n\n\n\n\n\nWarning\n\n\n\n\nTo create an object, give it a name followed by the assignment operator, followed by the value/data type.\nAssignment operator <-\nShortcut: “Alt + -” on PC, “Option + -” on Mac\n\n\n\n \n\n\n\n\n \nIn this image, you can see the different types of objects that we have and this is the best way to visualize. However, to really understand what is going on, you need to start writing code and start trying using this different type of objects to know them better. In the next lines, I’ll write explanations, examples and exercises."
  },
  {
    "objectID": "learn/rstudio/objects/index.html#numeric-values",
    "href": "learn/rstudio/objects/index.html#numeric-values",
    "title": "Understanding R Objects: Naming, Data Structures and Classes in R",
    "section": "Numeric values",
    "text": "Numeric values\nA numeric object can be stored as a number.\n\nx <- 6\n\nclass(x)\n\n[1] \"numeric\"\n\nx\n\n[1] 6"
  },
  {
    "objectID": "learn/rstudio/objects/index.html#character-values",
    "href": "learn/rstudio/objects/index.html#character-values",
    "title": "Understanding R Objects: Naming, Data Structures and Classes in R",
    "section": "Character values",
    "text": "Character values\nStores a sequence of characters, such as letters, numbers, and symbols. A character value is created by enclosing the sequence of characters within quotation marks, either single or double.\n\ncharacter <- \"Welcome to the Hertie Coding Club\"   # creating a character value\n\nCharacter values can be combined using the paste() or paste0() functions, which concatenate two or more character values into a single character value.\n\nx <- \"Welcome to\"\ny <- \"the Hertie Coding Club\"\nz <- paste(x, y, sep = \": \")\n\n\nclass(z)\n\n[1] \"character\"\n\nz\n\n[1] \"Welcome to: the Hertie Coding Club\""
  },
  {
    "objectID": "learn/rstudio/objects/index.html#create-a-numeric-vector",
    "href": "learn/rstudio/objects/index.html#create-a-numeric-vector",
    "title": "Understanding R Objects: Naming, Data Structures and Classes in R",
    "section": "Create a numeric vector",
    "text": "Create a numeric vector\n\nx <- c(1, 2, 3, 4, 5)\n\nx\n\n[1] 1 2 3 4 5"
  },
  {
    "objectID": "learn/rstudio/objects/index.html#access-elements-of-a-vector",
    "href": "learn/rstudio/objects/index.html#access-elements-of-a-vector",
    "title": "Understanding R Objects: Naming, Data Structures and Classes in R",
    "section": "Access elements of a vector",
    "text": "Access elements of a vector\nReturns the second element of x, which is 2\n\nx[2] \n\n[1] 2"
  },
  {
    "objectID": "learn/rstudio/objects/index.html#perform-arithmetic-operations",
    "href": "learn/rstudio/objects/index.html#perform-arithmetic-operations",
    "title": "Understanding R Objects: Naming, Data Structures and Classes in R",
    "section": "Perform arithmetic operations",
    "text": "Perform arithmetic operations\nAdds 2 to each element of x, resulting in the vector c(3, 4, 5, 6, 7)\n\nx + 2 \n\n[1] 3 4 5 6 7"
  },
  {
    "objectID": "learn/rstudio/objects/index.html#find-the-length-of-a-vector",
    "href": "learn/rstudio/objects/index.html#find-the-length-of-a-vector",
    "title": "Understanding R Objects: Naming, Data Structures and Classes in R",
    "section": "Find the length of a vector:",
    "text": "Find the length of a vector:\n\nlength(x) \n\n[1] 5"
  },
  {
    "objectID": "learn/rstudio/objects/index.html#modify-a-vector",
    "href": "learn/rstudio/objects/index.html#modify-a-vector",
    "title": "Understanding R Objects: Naming, Data Structures and Classes in R",
    "section": "Modify a vector",
    "text": "Modify a vector\nChanges the third element of x to 10\n\nx[3] <- 10\n\nx\n\n[1]  1  2 10  4  5"
  },
  {
    "objectID": "learn/rstudio/objects/index.html#apply-functions-to-a-vector",
    "href": "learn/rstudio/objects/index.html#apply-functions-to-a-vector",
    "title": "Understanding R Objects: Naming, Data Structures and Classes in R",
    "section": "Apply functions to a vector",
    "text": "Apply functions to a vector\nReturns the sum of the elements in x, which is 22\n\nsum(x) \n\n[1] 22\n\n\nReturns the mean (average) of the elements in x, which is 4.4\n\nmean(x)\n\n[1] 4.4\n\n\nReturns the maximum value in x, which is 10\n\nmax(x)\n\n[1] 10\n\n\nReturns the minimum value in x, which is 1\n\nmin(x)\n\n[1] 1\n\n\n \nIn addition to numeric values, you can put a wide variety of other data types in a vector in R. Here are some examples:"
  },
  {
    "objectID": "learn/rstudio/objects/index.html#character-values-1",
    "href": "learn/rstudio/objects/index.html#character-values-1",
    "title": "Understanding R Objects: Naming, Data Structures and Classes in R",
    "section": "Character values",
    "text": "Character values\n\nnames <- c(\"Hertie School\", \"Berlin\", \"Public Policy\")\n\nnames\n\n[1] \"Hertie School\" \"Berlin\"        \"Public Policy\""
  },
  {
    "objectID": "learn/rstudio/objects/index.html#logical-values",
    "href": "learn/rstudio/objects/index.html#logical-values",
    "title": "Understanding R Objects: Naming, Data Structures and Classes in R",
    "section": "Logical values",
    "text": "Logical values\n\nflags <- c(TRUE, FALSE, TRUE)\n\nflags\n\n[1]  TRUE FALSE  TRUE"
  },
  {
    "objectID": "learn/rstudio/objects/index.html#times",
    "href": "learn/rstudio/objects/index.html#times",
    "title": "Understanding R Objects: Naming, Data Structures and Classes in R",
    "section": "Times:",
    "text": "Times:\n\ntimes <- as.POSIXct(c(\"2022-01-01 10:00:00\", \"2022-01-01 11:00:00\", \"2022-01-01 12:00:00\"))\n\ntimes\n\n[1] \"2022-01-01 10:00:00 CET\" \"2022-01-01 11:00:00 CET\"\n[3] \"2022-01-01 12:00:00 CET\""
  },
  {
    "objectID": "learn/rstudio/objects/index.html#a-list-with-different-type-of-vectors",
    "href": "learn/rstudio/objects/index.html#a-list-with-different-type-of-vectors",
    "title": "Understanding R Objects: Naming, Data Structures and Classes in R",
    "section": "A list with different type of vectors",
    "text": "A list with different type of vectors\n\nmy_list <- list(numbers = c(1, 2, 3), names = c(\"Alejandro\", \"Eduardo\", \"Fernanda\"), statement = c(TRUE, FALSE, TRUE))\n\nmy_list\n\n$numbers\n[1] 1 2 3\n\n$names\n[1] \"Alejandro\" \"Eduardo\"   \"Fernanda\" \n\n$statement\n[1]  TRUE FALSE  TRUE"
  },
  {
    "objectID": "learn/rstudio/objects/index.html#access-an-element-of-the-list-using-indexing",
    "href": "learn/rstudio/objects/index.html#access-an-element-of-the-list-using-indexing",
    "title": "Understanding R Objects: Naming, Data Structures and Classes in R",
    "section": "Access an element of the list using indexing",
    "text": "Access an element of the list using indexing\nWe can access an element of the list using indexing, which is really useful when you are doing functions and storing results or calling them.\nHere this returns the second element of my_list, which is the character vector “names”\n\nmy_list[[2]]\n\n[1] \"Alejandro\" \"Eduardo\"   \"Fernanda\" \n\n\nor also we can access an element of the list using named indexing:\n\nmy_list[[\"names\"]]\n\n[1] \"Alejandro\" \"Eduardo\"   \"Fernanda\""
  },
  {
    "objectID": "learn/rstudio/objects/index.html#add-a-new-element-to-the-list",
    "href": "learn/rstudio/objects/index.html#add-a-new-element-to-the-list",
    "title": "Understanding R Objects: Naming, Data Structures and Classes in R",
    "section": "Add a new element to the list:",
    "text": "Add a new element to the list:\nAdds a new numeric vector “ages” to my_list\n\nmy_list[[\"ages\"]] <- c(25, 30, 35)\n\nWe can do the same even with a dataframe inside a list\n\ndf <- data.frame(name = c(\"Alejandro\", \"Eduardo\", \"Marifer\"), \n                 age = c(30, 27, 17)) # Create the dataframe\n\nmy_list[[\"my_df\"]] <- df\n\nmy_list\n\n$numbers\n[1] 1 2 3\n\n$names\n[1] \"Alejandro\" \"Eduardo\"   \"Fernanda\" \n\n$statement\n[1]  TRUE FALSE  TRUE\n\n$ages\n[1] 25 30 35\n\n$my_df\n       name age\n1 Alejandro  30\n2   Eduardo  27\n3   Marifer  17"
  },
  {
    "objectID": "learn/rstudio/objects/index.html#create-a-nested-list-with-two-elements",
    "href": "learn/rstudio/objects/index.html#create-a-nested-list-with-two-elements",
    "title": "Understanding R Objects: Naming, Data Structures and Classes in R",
    "section": "Create a nested list with two elements:",
    "text": "Create a nested list with two elements:\n\nnested_list <- list(numbers = c(1, 2, 3), list_2 = list(letter = \"A\", number = 42))\n\nnested_list\n\n$numbers\n[1] 1 2 3\n\n$list_2\n$list_2$letter\n[1] \"A\"\n\n$list_2$number\n[1] 42\n\n\nFor access a nested element of the list:\n\nnested_list[[\"list_2\"]][[\"number\"]]  \n\n[1] 42\n\n\nAs you can see, we can access the outputs of the list we want. This is useful since you can apply functions to retrieve your data from a nested list or access to a specific output of your model, for example."
  },
  {
    "objectID": "learn/rstudio/objects/index.html#createing-a-matrix",
    "href": "learn/rstudio/objects/index.html#createing-a-matrix",
    "title": "Understanding R Objects: Naming, Data Structures and Classes in R",
    "section": "Createing a matrix",
    "text": "Createing a matrix\nCreate a matrix with three rows and four columns:\n\nm_example <- matrix(1:12, nrow = 3, ncol = 4)\n\nm_example\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    4    7   10\n[2,]    2    5    8   11\n[3,]    3    6    9   12"
  },
  {
    "objectID": "learn/rstudio/objects/index.html#access-an-element-of-the-matrix-using-indexing",
    "href": "learn/rstudio/objects/index.html#access-an-element-of-the-matrix-using-indexing",
    "title": "Understanding R Objects: Naming, Data Structures and Classes in R",
    "section": "Access an element of the matrix using indexing",
    "text": "Access an element of the matrix using indexing\nReturns the element in the second row and third column of my_matrix, which is 7\n\nm_example[2, 3] \n\n[1] 8"
  },
  {
    "objectID": "learn/rstudio/objects/index.html#modify-an-element-of-the-matrix",
    "href": "learn/rstudio/objects/index.html#modify-an-element-of-the-matrix",
    "title": "Understanding R Objects: Naming, Data Structures and Classes in R",
    "section": "Modify an element of the matrix",
    "text": "Modify an element of the matrix\nChanges the element in the first row and fourth column of my_matrix to 20\n\nm_example[1, 4] <- 20  \n\nm_example\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    4    7   20\n[2,]    2    5    8   11\n[3,]    3    6    9   12"
  },
  {
    "objectID": "learn/rstudio/objects/index.html#create-an-array-with-three-dimensions",
    "href": "learn/rstudio/objects/index.html#create-an-array-with-three-dimensions",
    "title": "Understanding R Objects: Naming, Data Structures and Classes in R",
    "section": "Create an array with three dimensions",
    "text": "Create an array with three dimensions\n\narr_example <- array(1:24, dim = c(2, 3, 4))\n\narr_example\n\n, , 1\n\n     [,1] [,2] [,3]\n[1,]    1    3    5\n[2,]    2    4    6\n\n, , 2\n\n     [,1] [,2] [,3]\n[1,]    7    9   11\n[2,]    8   10   12\n\n, , 3\n\n     [,1] [,2] [,3]\n[1,]   13   15   17\n[2,]   14   16   18\n\n, , 4\n\n     [,1] [,2] [,3]\n[1,]   19   21   23\n[2,]   20   22   24"
  },
  {
    "objectID": "learn/rstudio/objects/index.html#access-an-element-of-the-array-using-indexing",
    "href": "learn/rstudio/objects/index.html#access-an-element-of-the-array-using-indexing",
    "title": "Understanding R Objects: Naming, Data Structures and Classes in R",
    "section": "Access an element of the array using indexing",
    "text": "Access an element of the array using indexing\nReturns the element in the second row, third column, and fourth layer of my_array, which is 23\n\narr_example[2, 3, 4]\n\n[1] 24"
  },
  {
    "objectID": "learn/rstudio/objects/index.html#modify-an-element-of-the-array",
    "href": "learn/rstudio/objects/index.html#modify-an-element-of-the-array",
    "title": "Understanding R Objects: Naming, Data Structures and Classes in R",
    "section": "Modify an element of the array",
    "text": "Modify an element of the array\nChanges the element in the second row, second column, and first layer of arr_example to 10\n\narr_example[2, 2, 1] <- 10 \n\narr_example\n\n, , 1\n\n     [,1] [,2] [,3]\n[1,]    1    3    5\n[2,]    2   10    6\n\n, , 2\n\n     [,1] [,2] [,3]\n[1,]    7    9   11\n[2,]    8   10   12\n\n, , 3\n\n     [,1] [,2] [,3]\n[1,]   13   15   17\n[2,]   14   16   18\n\n, , 4\n\n     [,1] [,2] [,3]\n[1,]   19   21   23\n[2,]   20   22   24"
  },
  {
    "objectID": "learn/rstudio/objects/index.html#create-a-data-frame-multiple-ways",
    "href": "learn/rstudio/objects/index.html#create-a-data-frame-multiple-ways",
    "title": "Understanding R Objects: Naming, Data Structures and Classes in R",
    "section": "Create a Data Frame: multiple ways",
    "text": "Create a Data Frame: multiple ways\n1.- Using data.frame() function: This is the most common way to create a data frame in R. You can put as many vectors (variables) as you want.\n\ndf <- data.frame(x = c(1, 2, 3), \n                 y = c(\"a\", \"b\", \"c\"), \n                 z = c(TRUE, FALSE, TRUE))\n\n2.- Using read_csv2() function: You can also create a data frame by importing data from an external file using the read.table() or read.csv() function.\n\ndf <- read.table(\"data.txt\", header = TRUE)\n\n3.- Using read_excel() function from the readxl package\n\nlibrary(readxl)\ndf <- read_excel(\"data.xlsx\")\n\n4.- Using tibble() function from the tibble package\n\nlibrary(tibble)\ndf <- tibble(x = c(1, 2, 3), y = c(\"a\", \"b\", \"c\"), z = c(TRUE, FALSE, TRUE))\n\nYou can check our other tutorials to handle data frames and start practicing. We also recommend these books from the website for you to go into more detail.\n\n\n  \n    \n      \n  \n  \n    \n      \n  \n\n\nNo matching items"
  },
  {
    "objectID": "learn/rstudio/social_media_scraping/index.html",
    "href": "learn/rstudio/social_media_scraping/index.html",
    "title": "Introduction to Social Media Scraping",
    "section": "",
    "text": "NEWS\n\n\n\nWith the next Twitter regulations, The free package comes with rate-limited access to v2 tweet posting and media upload endpoints, with a posting limit of 1,500 tweets per month at the app level. If you want to access to posting tweets are up to 3,000 per month, and for reading, it’s up to 10,000 tweets per month, you will need to pay 100 USD per month. However, you can sill acces to databases and use this tutorial to analyze text in general."
  },
  {
    "objectID": "learn/rstudio/social_media_scraping/index.html#loading-in-packages-and-authorizing-rtweet",
    "href": "learn/rstudio/social_media_scraping/index.html#loading-in-packages-and-authorizing-rtweet",
    "title": "Introduction to Social Media Scraping",
    "section": "Loading in packages and authorizing rtweet",
    "text": "Loading in packages and authorizing rtweet\nSo the first thing we want to do is load in the packages we’ll be using to scrape and manipulate our data. The most important of those is rtweet, which is the one we’ll be using to interact with the Twitter API.\nIn order to scrape tweets, you’ll need a Twitter developer account and have to make a Twitter app. This is actually a pretty simple process (and won’t require any coding). Here’s a step-by-step guide\n\npacman::p_load(rtweet, tidyverse, ggplot2, utils, tm, SnowballC, caTools, \n               rpart, topicmodels, tidytext, wordcloud, lexicon, reshape2,\n               sentimentr)\n\nRunning the code above (without the #’s) will prompt a dialogue box to pop up on your screen asking you for a bearer token. You can find that on the Twitter developer page. I made the last two lines into comments so that this can be knit into HTML smoothly."
  },
  {
    "objectID": "learn/rstudio/social_media_scraping/index.html#corpus",
    "href": "learn/rstudio/social_media_scraping/index.html#corpus",
    "title": "Introduction to Social Media Scraping",
    "section": "Corpus",
    "text": "Corpus\nIn natural language processing (NLP), a corpus is a collection of written or spoken language that is used as a basis for analysis. A corpus can be made up of many different types of texts, including books, articles, speeches, social media posts, and more. Here, we will make a corpus of documents using just the full_text part of green tweets\n\ncorpus1 <- Corpus(VectorSource(green$full_text))\n\nNow we need to clean our text a bit. Change to lower case and remove punctuation!\n\ncorpus1 <- tm_map(corpus1, tolower)\ncorpus1 <- tm_map(corpus1, removePunctuation)\n#We need to remove stop words to get meaningful results from this exercise. \n#We'll remove words like \"me\", \"is\", \"was\"\nstopwords(\"english\")[1:50]\n\n [1] \"i\"          \"me\"         \"my\"         \"myself\"     \"we\"        \n [6] \"our\"        \"ours\"       \"ourselves\"  \"you\"        \"your\"      \n[11] \"yours\"      \"yourself\"   \"yourselves\" \"he\"         \"him\"       \n[16] \"his\"        \"himself\"    \"she\"        \"her\"        \"hers\"      \n[21] \"herself\"    \"it\"         \"its\"        \"itself\"     \"they\"      \n[26] \"them\"       \"their\"      \"theirs\"     \"themselves\" \"what\"      \n[31] \"which\"      \"who\"        \"whom\"       \"this\"       \"that\"      \n[36] \"these\"      \"those\"      \"am\"         \"is\"         \"are\"       \n[41] \"was\"        \"were\"       \"be\"         \"been\"       \"being\"     \n[46] \"have\"       \"has\"        \"had\"        \"having\"     \"do\"        \n\ncorpus1 <- tm_map(corpus1, removeWords, (stopwords(\"english\")))\n#We need to clean the words in the corpus further by \"stemming\" words\n#A word like \"understand\" and \"understands\" will both become \"understand\"\ncorpus1 <- tm_map(corpus1, stemDocument)"
  },
  {
    "objectID": "learn/rstudio/social_media_scraping/index.html#document-term-matrix",
    "href": "learn/rstudio/social_media_scraping/index.html#document-term-matrix",
    "title": "Introduction to Social Media Scraping",
    "section": "Document Term Matrix",
    "text": "Document Term Matrix\nSo, a DTM is a way of representing a collection of text documents quantitativelythat allows us to do some cool stuff with them. It’s basically a matrix where the rows correspond to the documents in the collection, and the columns correspond to the unique words or terms that appear in the documents. Each cell in the matrix represents the frequency of a particular term in a particular document.\n\n#creates a document term matrix, which is necessary for building a topic model\nDTM1 <- DocumentTermMatrix(corpus1)\n#Here we can see the most frequently used terms\nfrequent_ge_20 <- findFreqTerms(DTM1, lowfreq = 100)\nfrequent_ge_20\n\n [1] \"amp\"       \"green\"     \"like\"      \"store\"     \"day\"       \"…\"        \n [7] \"’s\"        \"light\"     \"one\"       \"year\"      \"figur\"     \"red\"      \n[13] \"buddha\"    \"fasc1nat\"  \"four\"      \"f…\"        \"philippin\" \"pray\"     \n[19] \"purchas\"   \"spent\"     \"woman\""
  },
  {
    "objectID": "learn/rstudio/social_media_scraping/index.html#lets-create-the-topic-model-well-start-with-5-topics",
    "href": "learn/rstudio/social_media_scraping/index.html#lets-create-the-topic-model-well-start-with-5-topics",
    "title": "Introduction to Social Media Scraping",
    "section": "Let’s create the topic model! We’ll start with 5 topics",
    "text": "Let’s create the topic model! We’ll start with 5 topics\nThe code snippet performs topic modeling on a corpus of text data represented as a Document-Term Matrix (DTM) using the Latent Dirichlet Allocation (LDA) algorithm. The LDA() function from the topic models package is used to create a model with 7 topics and a specified random seed for reproducibility. The resulting model is stored in the green_lda1 object.\n\n#Perform LDA topic modeling on a Document-Term Matrix (DTM) with 7 topics\ngreen_lda1 <- LDA(DTM1, k = 7, control = list(seed = 1234))\n\n#Print the model summary\ngreen_lda1\n\nA LDA_VEM topic model with 7 topics.\n\n#Convert the model's beta matrix to a tidy format\ngreen_topics1 <- tidy(green_lda1, matrix = \"beta\")\n\ngreen_top_terms1 <- green_topics1 %>%\n  group_by(topic) %>% #Group the terms by topic\n  slice_max(beta, n = 10) %>% #Top 10 terms with the highest probabilities\n  ungroup() %>% #Remove the grouping attribute from the data frame\n  arrange(topic, -beta) #Sort the data frame by topic index and term probability"
  },
  {
    "objectID": "learn/rstudio/social_media_scraping/index.html#word-cloud-of-biden-tweets",
    "href": "learn/rstudio/social_media_scraping/index.html#word-cloud-of-biden-tweets",
    "title": "Introduction to Social Media Scraping",
    "section": "Word Cloud of Biden Tweets",
    "text": "Word Cloud of Biden Tweets\n\nCode# Create custom color palette\nmy_palette <- brewer.pal(8, \"Dark2\")\n\n# Create word cloud with larger font size and custom layout\nwordcloud(words_data2$word, \n          words_data2$n, \n          max.words = 200, \n          colors = my_palette, \n          scale = c(5, 0.3),\n          random.order = FALSE,\n          rot.per = 0.25,\n          random.color = TRUE,\n          main = \"Word Cloud of Biden Tweets\")"
  },
  {
    "objectID": "learn/rstudio/social_media_scraping/index.html#comparison-cloud-of-biden-tweets-by-sentiment",
    "href": "learn/rstudio/social_media_scraping/index.html#comparison-cloud-of-biden-tweets-by-sentiment",
    "title": "Introduction to Social Media Scraping",
    "section": "Comparison Cloud of Biden Tweets by Sentiment",
    "text": "Comparison Cloud of Biden Tweets by Sentiment\nNow let’s make a word cloud from those tweets but highlight which words are positive and which are negative\n\n#Select and tokenize words\nwords_data <- biden_tweets %>% \n  select(text) %>%\n  unnest_tokens(word, text) \n\n#Get sentiment scores for each word using the bing lexicon\nsentiment_scores <- words_data2 %>%\n  inner_join(get_sentiments(\"bing\"))\n\n#Count the number of words in each sentiment category\nsentiment_counts <- sentiment_scores %>%\n  count(sentiment, sort = TRUE)\n\n#Create a list of profanity words to remove from the dataset\nprofanity_list <- unique(tolower(lexicon::profanity_alvarez))\n\n#Filter out stop words and profanity words from the dataset\nfiltered_words_data <- words_data %>%\n  filter(!word %in% c('https', 't.co', 'he\\'s', 'i\\'m', 'it\\'s', profanity_list))\n\n#Get sentiment scores for each filtered word using the bing lexicon\nfiltered_sentiment_scores <- filtered_words_data %>%\n  inner_join(get_sentiments(\"bing\"))"
  },
  {
    "objectID": "learn/rstudio/social_media_scraping/index.html#cloud",
    "href": "learn/rstudio/social_media_scraping/index.html#cloud",
    "title": "Introduction to Social Media Scraping",
    "section": "Cloud",
    "text": "Cloud\n\nCode#Count the number of filtered words with each sentiment score\nword_sentiment_counts <- filtered_sentiment_scores %>%\n  count(word, sentiment, sort = TRUE) %>%\n  acast(word ~ sentiment, value.var = \"n\", fill = 0)\n\n#Create a comparison cloud using the word and sentiment counts\ncomparison.cloud(word_sentiment_counts, \n                  colors = c(\"red\", \"blue\"),\n                  max.words = Inf)"
  },
  {
    "objectID": "learn/rstudio/Install-r-studio/index.html",
    "href": "learn/rstudio/Install-r-studio/index.html",
    "title": "Install R and Rstudio: why R rocks 💻 🔥",
    "section": "",
    "text": "Install R and Rstudio: why R rocks\n\n\n\n\n\n\n\n\n\nR provides a versatile and powerful toolset for users of all skill levels, making it the go-to choice if you’re looking for a cutting-edge solution for your data analysis needs. R has everything you need to advance your data analysis, regardless of your experience level or where you are in your career. We assure you won’t be disappointed, so why not join the millions of happy users who have already switched to R?\nR is a free, open-source programming language that is widely used in data analysis and statistical computing. RStudio is an integrated development environment (IDE) that makes it easier to write and run R code. Installing R and RStudio is straightforward and can be done in a few simple steps:\n\nWhy R?\nDue to its many benefits in statistical computing and data analysis, R is a strong and flexible programming language that has gained popularity recently. Here are some of the main benefits of using R:\n\nOpen source software: R is open source, so users can access and alter the source code to tailor the program to their needs.\n\n\n\n\n\n\n\n\n\n\n\n\n\nPackages: Users can use R’s extensive package library to add functionality for specialized tasks like tables, visualization, and data manipulation. Right now, there are more than 18,000 packages available.\n\n\n\n\n\n\n\nEasy to use: R has an intuitive user interface that makes it simple for new users to learn and offers advanced features for seasoned users.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStep 1: Install R\nFirst, you need to install R on your computer. You can download the latest version of R from the Comprehensive R Archive Network (CRAN) website. Follow these steps:\n\nGo to the CRAN website and click on the “Download R for (Windows/MacOS/Linux)” link.\nChoose your operating system from the list and click on the corresponding link to download the installation file.\nOnce the file is downloaded, run the installation program and follow the instructions.\n\n\n\nStep 2: Install RStudio\nThe latest version of RStudio can be downloaded from the RStudio website. After you have installed R, you can install RStudio, an optional but highly recommended IDE for R. The following actions should be taken.\n\nVisit the RStudio website and select “RStudio Desktop” from the list of available products.\nFrom the list, select your operating system, and then click the link to download the installation file.\nRun the installation program after the file has been downloaded, then adhere to the prompts.\n\n\n\nStep 3: Launch RStudio\nOnce you have installed R and RStudio, you can launch RStudio by double-clicking on its icon . When you first launch RStudio, you will be prompted to select a version of R to use. If you have installed only one version of R, it should be automatically selected. Otherwise, you can choose the version of R that you want to use.\n\n\n\n\n\n\nReady\n\n\n\nYou’ve now successfully installed R and RStudio on your computer. Now that R and RStudio are installed, you can begin writing and running R code."
  },
  {
    "objectID": "learn/rstudio/stata_to_r/index.html",
    "href": "learn/rstudio/stata_to_r/index.html",
    "title": "Making the Transition? A Guide for switching from Stata to R",
    "section": "",
    "text": "Who doesn’t remember their first love? In my case, in the coding world, my first love was Stata. I clearly remember my first job as a research assistant to Laura Atuesta. Learning Stata implied an important learning curve since this language was used in my university for my classes, my work, and research. I did my bachelor’s thesis with Stata, and, being honest, I just have great memories using Stata because it was the first time that I’ve feel capable of doing multiple things. There my curiosity for data science and coding started. However, like any other Story love (that may be doesn’t end well), I met R. I would say with this language my interest and passion for coding exploded. Since then, I stopped using Stata and fall in love completely for R. Syntaxis, open-source building community and the approach that you can have with this language are just one of the multiple reasons why I decided to keep learning with R. It doesn’t matter what happens, Stata will be always in the bottom of my heart and my first love since it was the first coding language that I learned.\nBecause of this and because I know that different people and scholars are using Stata and they are curious about what R offers, here is an essential guide of commands for doing some data wrangling, analysis, and running some models. Of course, I don’t cover plenty of things, but this is just to show the differences between using R and Stata. I’m sorry if I don’t use the new Stata approaches since I learned the version 11º or 12º and now the are in the 17º version, however, the commands still can be useful.\nWe are going to work a lot with the dplyrpackage. You need to load the package just once when you open your environment. If you have any question, please check our other material to start learning R. However, the best way to learn is try different approaches (;"
  },
  {
    "objectID": "learn/rstudio/stata_to_r/index.html#csv-files",
    "href": "learn/rstudio/stata_to_r/index.html#csv-files",
    "title": "Making the Transition? A Guide for switching from Stata to R",
    "section": "CSV Files",
    "text": "CSV Files\n\n\n\n\n\n\n/*Import csv file*/\nimport delimited \"my_data.csv\", clear\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(readr)\n\n#Use read_csv2\ndf_data <- read_csv2(\"data.csv\")\n\n#Using read.table function with comma separator\ndf_data <- read.table(\"my_data.csv\", \n                      sep = \",\", \n                      header = TRUE)"
  },
  {
    "objectID": "learn/rstudio/stata_to_r/index.html#excel-files",
    "href": "learn/rstudio/stata_to_r/index.html#excel-files",
    "title": "Making the Transition? A Guide for switching from Stata to R",
    "section": "Excel Files",
    "text": "Excel Files\n\n\n\n\n\n\n/*Import excel file*/\nimport excel \"df_data.xlsx\", \nsheet(\"Sheet1\") firstrow clear\n\n\n\n\n\n\n\n\n\n\n\n#With readxl package\nlibrary(readxl)\ndf_data <- read_excel(\"my_data.xlsx\", \n                      sheet = \"Sheet1\")\n\n#With openxlsx package\nlibrary(openxlsx)\ndf_data <- read.xlsx(\"my_data.xlsx\", \n                     sheet = \"Sheet1\")"
  },
  {
    "objectID": "learn/rstudio/stata_to_r/index.html#stata-files-.dta",
    "href": "learn/rstudio/stata_to_r/index.html#stata-files-.dta",
    "title": "Making the Transition? A Guide for switching from Stata to R",
    "section": "Stata Files (.dta)",
    "text": "Stata Files (.dta)\n\n\n\n\n\n\n/*Import excel file*/\nuse \"df_data.dta\", clear\n\n\n\n\n\n\n\n\n\n\n\n#Load the package\nlibrary(haven)            \n\ndf_data <- read_dta(\"df_data.dta\")"
  },
  {
    "objectID": "learn/rstudio/stata_to_r/index.html#missing-data",
    "href": "learn/rstudio/stata_to_r/index.html#missing-data",
    "title": "Making the Transition? A Guide for switching from Stata to R",
    "section": "Missing Data",
    "text": "Missing Data\n\n\n\n\n\n\n/* Provides the structure of the dataset */\nmissing variable1 variable2 variable3\n\n\n\n\n\n\n\n\n\n\n\n\n#Check missing data for our entire database\nis.na(df_data)\n\n#Check missing data for our entire database\nis.na(df_data$variable1)"
  },
  {
    "objectID": "learn/rstudio/stata_to_r/index.html#rename-variables",
    "href": "learn/rstudio/stata_to_r/index.html#rename-variables",
    "title": "Making the Transition? A Guide for switching from Stata to R",
    "section": "Rename variables",
    "text": "Rename variables\n\n\n\n\n\n\n/* How to rename */\nrename oldname newname\n\nrename lastname lastname2\nrename firstname firstname2\nrename studentstatus studentstatus2\nrename averagescoregrade avgscore\n\n\n\n\n\n\n\n\n\n\n\n\n#Rename the variables of our data\nnames(df_data) <- c(\"newvar1\", \"newvar2\")\n\n#With the dplyr package\n\nlibrary(dplyr)\ndf_data_final <- rename(df_data, \n                        newvar1 = var1, \n                        newvar2 = var2)"
  },
  {
    "objectID": "learn/rstudio/stata_to_r/index.html#label-variables",
    "href": "learn/rstudio/stata_to_r/index.html#label-variables",
    "title": "Making the Transition? A Guide for switching from Stata to R",
    "section": "Label variables",
    "text": "Label variables\n\n\n\n\n\n\nlabel variable w \"Weight\"\nlabel variable y \"Output\"\nlabel variable x1 \"Predictor 1\"\nlabel variable x2 \"Predictor 2\"\nlabel variable age \"Age\"\nlabel variable sex \"Gender\"\n\n\n\n\n\n\n\n\n\n\n\n#Load labelled package\nlibrary(labelled)\n\n#Define the value labels for the codes\nlabels <- c(\"Option 1\", \"Option 2\", \n            \"Option 3\", \"Option 4\", \n            \"Option 5\")\ndf_data$code <- labelled(df_data$code, \n                         labels = labels)"
  },
  {
    "objectID": "learn/rstudio/stata_to_r/index.html#value-labels",
    "href": "learn/rstudio/stata_to_r/index.html#value-labels",
    "title": "Making the Transition? A Guide for switching from Stata to R",
    "section": "Value labels",
    "text": "Value labels\n\n\n\n\n\n\n/* Value labels for the codes */\nlabel define label1 1 \"Option 1\" \n2 \"Option 2\" 3 \"Option 3\" 4 \"Option 4\" \n5 \"Option 5\"\n\n/* Assign the value labels to the codes */\nlabel values code label1\n\n\n\n\n\n\n\n\n\n\n\n#Load labelled package\nlibrary(labelled)\n\n#Define the value labels for the codes\nlabels <- c(\"Option 1\", \"Option 2\", \n            \"Option 3\", \"Option 4\", \n            \"Option 5\")\ndf_data$code <- labelled(df_data$code, \n                         labels = labels)\n\n\n#Define the value labels for the codes\nlabels <- c(\"Option 1\", \"Option 2\", \n            \"Option 3\", \"Option 4\", \n            \"Option 5\")\ndf_data$code <- factor(df_data$code, \n                       levels = 1:5, \n                       labels = labels)\n\nIn this approach, you can assign values to numeric or character variables"
  },
  {
    "objectID": "learn/rstudio/stata_to_r/index.html#group-variables",
    "href": "learn/rstudio/stata_to_r/index.html#group-variables",
    "title": "Making the Transition? A Guide for switching from Stata to R",
    "section": "Group variables",
    "text": "Group variables\n\n\n\n\n\n\n/* Value labels for the codes */\ncollapse (mean) var1, by(var2, var3)\n\nlist var2 var3 var1\n\n\n\n\n\n\n\n\n\n\n\n#Load dplyr package\nlibrary(dplyr)\n\n#We group the data by variables 2 and 3, \n#calculate the mean of variable 1\ndf_data_group <- df_data %>%\n  group_by(var2, var3) %>%\n  summarise(mean_var1 = mean(var1))"
  },
  {
    "objectID": "learn/rstudio/stata_to_r/index.html#merge-two-datasets",
    "href": "learn/rstudio/stata_to_r/index.html#merge-two-datasets",
    "title": "Making the Transition? A Guide for switching from Stata to R",
    "section": "Merge two datasets",
    "text": "Merge two datasets\n\n\n\n\n\n\n/* Exact match on the key variable(s). */\nuse dataset1.dta, clear\nmerge 1:1 id using dataset2.dta\n/* Each observation in the first dataset */\nmerge 1:m id using dataset2.dta\n/* Each observation in the second dataset */\nmerge m:1 id using dataset2.dta\n/* Each observation many-to-many merge */\nmerge m:1 id using dataset2.dta\nRemember that we need to have our data1 in the same path\n\n\n\n\n\n\n\n\n\n\n\n#Load dplyr package\nlibrary(dplyr)\n\n#1:1 using inner join\ndf_merged_inner <- inner_join(df_1, df_1, \n                              by = \"id1\")\n\n#1:m using left join\ndf_merged_left <- left_join(df_1, df_1, \n                            by = \"id1\")\n\n#m:1 using right join\ndf_merged_right <- right_join(df_1, df_1, \n                              by = \"id1\")\n\n#m:m using full join\ndf_merged_full <- full_join(df_1, df_1, \n                            by = c(\"id1\", \n                                   \"id2\"))\n#You can merge with more tha one variable"
  },
  {
    "objectID": "learn/rstudio/stata_to_r/index.html#create-sequenceids",
    "href": "learn/rstudio/stata_to_r/index.html#create-sequenceids",
    "title": "Making the Transition? A Guide for switching from Stata to R",
    "section": "Create sequence/ids",
    "text": "Create sequence/ids\n\n\n\n\n\n\n/* Sequence of numbers from 1 to n */\ngen seq = _n\n\n/* Sequence with the total number of \nobservations */\n\ngen total_seq = _N\n\n\n\n\n\n\n\n\n\n\n\nv_seq <- seq(from = 1, to = 10, by = 1)\n\n#Load dplyr package\nlibrary(dplyr)\n\ndf_final <- df %>%\n  mutate(id = 1:n())"
  },
  {
    "objectID": "learn/rstudio/stata_to_r/index.html#drop-variables",
    "href": "learn/rstudio/stata_to_r/index.html#drop-variables",
    "title": "Making the Transition? A Guide for switching from Stata to R",
    "section": "Drop variables",
    "text": "Drop variables\n\n\n\n\n\n\n/* Drop variable */\ndrop var1 var2\n\n/* Drop all variable and keep */\ndrop _all\nkeep var1 var2 var3\n\n\n\n\n\n\n\n\n\n\n\n#Load dplyr package\nlibrary(dplyr)\n\n#Drop some variables\ndf_new_data <- df_old %>% select(-var1, -var2)\n\n#Keep specific variables\ndf_new_data <- df_old %>% select(var1, var2)"
  },
  {
    "objectID": "learn/rstudio/stata_to_r/index.html#summary",
    "href": "learn/rstudio/stata_to_r/index.html#summary",
    "title": "Making the Transition? A Guide for switching from Stata to R",
    "section": "Summary",
    "text": "Summary\n\n\n\n\n\n\n/* Summary of variables of interest*/\nsummarize var1 var2 var3\n\n\n\n\n\n\n\n\n\n\n\n\n#Summary for entire data\nsummary(dataset)\n\n#Summary for a variable\nsummary(dataset$variable)"
  },
  {
    "objectID": "learn/rstudio/stata_to_r/index.html#linear-model",
    "href": "learn/rstudio/stata_to_r/index.html#linear-model",
    "title": "Making the Transition? A Guide for switching from Stata to R",
    "section": "Linear Model",
    "text": "Linear Model\n\n\n\n\n\n\n/* Fit a linear model */\nregress mpg weight length foreign\n\n/* Print summary */\nestimates table\n\n\n\n\n\n\n\n\n\n\n\n#Fit a linear model\nmodel_lm <- lm(mpg ~ wt + qsec + vs, \n               data = df_my_data)\n\n#Print summary\nsummary(model_lm)"
  },
  {
    "objectID": "learn/rstudio/stata_to_r/index.html#logistic-model",
    "href": "learn/rstudio/stata_to_r/index.html#logistic-model",
    "title": "Making the Transition? A Guide for switching from Stata to R",
    "section": "Logistic Model",
    "text": "Logistic Model\n\n\n\n\n\n\n/* Fit a logistic regression model */\nlogit foreign weight length\n\n/* Print summary */\nestimates table\n\n\n\n\n\n\n\n\n\n\n\n#Fit a logistic regression model\nmodel_log <- glm(vs ~ wt + qsec, \n                 data = df_my_data, \n                 family = binomial())\n\n#Print summary\nsummary(model)"
  },
  {
    "objectID": "learn/rstudio/stata_to_r/index.html#poisson-model",
    "href": "learn/rstudio/stata_to_r/index.html#poisson-model",
    "title": "Making the Transition? A Guide for switching from Stata to R",
    "section": "Poisson Model",
    "text": "Poisson Model\n\n\n\n\n\n\n/* Fit a Poisson regression model */\npoisson accidents weight length foreign\n\n/* Print summary */\nestimates table\n\n\n\n\n\n\n\n\n\n\n\n#Fit a Poisson regression model\nmodel_poiss <- glm(am ~ wt + hp, \n                   data = df_my_data, \n                   family = poisson())\n\n#Print summary\nsummary(model)"
  },
  {
    "objectID": "learn/rstudio/stata_to_r/index.html#scatter-plot",
    "href": "learn/rstudio/stata_to_r/index.html#scatter-plot",
    "title": "Making the Transition? A Guide for switching from Stata to R",
    "section": "Scatter plot",
    "text": "Scatter plot\n\n\n\n\n\n\n/* Create scatter plot */\nscatter price mpg\n\n\n\n\n\n\n\n\n\n\n\n# Load data and ggplot2\nlibrary(ggplot2)\ndata(df_my_data)\n\n#Create scatter plot\nggplot(df_my_data, aes(x = mpg, y = wt)) + \n  geom_point() + #Here is the scatter\n  xlab(\"Miles per gallon\") +\n  ylab(\"Weight\")"
  },
  {
    "objectID": "learn/rstudio/stata_to_r/index.html#line-plot",
    "href": "learn/rstudio/stata_to_r/index.html#line-plot",
    "title": "Making the Transition? A Guide for switching from Stata to R",
    "section": "Line plot",
    "text": "Line plot\n\n\n\n\n\n\n/* Create Line plot */\ntwoway line le_w le_y, xlabel(1950(10)2010)\n\n\n\n\n\n\n\n\n\n\n\n# Load data and ggplot2\nlibrary(ggplot2)\ndata(df_my_data)\n\n#Create line plot\nggplot(df_my_data, aes(x = year, y = pop)) + \n  geom_line() + #Here is the line\n  xlab(\"Year\") +\n  ylab(\"Population\")"
  },
  {
    "objectID": "learn/rstudio/stata_to_r/index.html#bar-plot",
    "href": "learn/rstudio/stata_to_r/index.html#bar-plot",
    "title": "Making the Transition? A Guide for switching from Stata to R",
    "section": "Bar plot",
    "text": "Bar plot\n\n\n\n\n\n\n/* Create a Bar plot */\ngraph bar (count) rep78, over(foreign)\n\n\n\n\n\n\n\n\n\n\n\n# Load data and ggplot2\nlibrary(ggplot2)\ndata(df_my_data)\n\n#Create bar chart\nggplot(data = df_my_data, \n       aes(x = factor(cyl))) +\n  geom_bar() + #Here is the bar\n  xlab(\"Number of cylinders\") +\n  ylab(\"Count\")\n\n\n\n \nI also want to provide a good cheat sheet that contains more information about the differences between Stata and R."
  },
  {
    "objectID": "learn/python.html",
    "href": "learn/python.html",
    "title": "Learn Python",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\n\nStop using webites to transform your PDFs into text. Do it by your own with Python and extract text and tables from your documents.\n\n\n\n\nPDF\n\n\nText\n\n\nTransform\n\n\n \n\n\n\n\nApr 18, 2023\n\n\nJorge Roa\n\n\n7 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "learn/rstudio.html",
    "href": "learn/rstudio.html",
    "title": "Learn R",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\n\nIf you use Stata for your analysis, but you are curious or want to switch to the R world, this is your guide for it.\n\n\n\n\nR\n\n\nStata\n\n\nTransition\n\n\n \n\n\n\n\nApr 23, 2023\n\n\nJorge Roa\n\n\n11 min\n\n\n\n\n\n\n  \n\n\n\n\n\nLearn the basic tools for scraping Twitter Data in R\n\n\n\n\nTwitter\n\n\nWebscraping\n\n\nText\n\n\n \n\n\n\n\nApr 18, 2023\n\n\nLukas Lehmann\n\n\n11 min\n\n\n\n\n\n\n  \n\n\n\n\n\nThis is why R is so powerful: all kind of objects and possibilites. Naming objects, understand structures is crucial to learn\n\n\n\n\nRstudio\n\n\nObjects\n\n\n \n\n\n\n\nApr 16, 2023\n\n\nJorge Roa\n\n\n17 min\n\n\n\n\n\n\n  \n\n\n\n\n\nLearn the basics of R: open a project, setting a working directory and navigate RStudio interface\n\n\n\n\nRstudio\n\n\nInterface\n\n\n \n\n\n\n\nApr 12, 2023\n\n\nJorge Roa\n\n\n8 min\n\n\n\n\n\n\n  \n\n\n\n\n\nUnlock the power of data analysis and statistical computing with R and RStudio! Whether you are a student of public policy or a seasoned professional.\n\n\n\n\nR\n\n\nRStudio\n\n\nAccesibility\n\n\nInstall\n\n\n \n\n\n\n\nMar 2, 2023\n\n\nJorge Roa\n\n\n2 min\n\n\n\n\n\n\n  \n\n\n\n\n\nMultithreading offers faster and more efficient data processing, allowing for quicker analysis of complex datasets.\n\n\n\n\nMultithread\n\n\nData table\n\n\n \n\n\n\n\nJul 28, 2022\n\n\nJorge Roa, Fernando Alarid-Escudero\n\n\n3 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "members/statute/statute.html#section-1-eligibility",
    "href": "members/statute/statute.html#section-1-eligibility",
    "title": "Hertie Coding Club Statutes",
    "section": "Section 1: Eligibility",
    "text": "Section 1: Eligibility\nMembership in the Hertie Coding Club is open to all members of the Hertie community, including students, faculty, staff, and alumni, regardless of their background or experience in coding."
  },
  {
    "objectID": "members/statute/statute.html#section-2-responsibilities",
    "href": "members/statute/statute.html#section-2-responsibilities",
    "title": "Hertie Coding Club Statutes",
    "section": "Section 2: Responsibilities",
    "text": "Section 2: Responsibilities\nMembers are expected to actively participate in club activities, contribute to a positive learning environment, and maintain a respectful attitude towards fellow members."
  },
  {
    "objectID": "members/statute/statute.html#section-1-composition",
    "href": "members/statute/statute.html#section-1-composition",
    "title": "Hertie Coding Club Statutes",
    "section": "Section 1: Composition",
    "text": "Section 1: Composition\nThe Executive Committee shall consist of the following positions: President, Vice President, Secretary, Treasurer, and Communications Officer."
  },
  {
    "objectID": "members/statute/statute.html#section-2-duties",
    "href": "members/statute/statute.html#section-2-duties",
    "title": "Hertie Coding Club Statutes",
    "section": "Section 2: Duties",
    "text": "Section 2: Duties\n\nPresident: Oversee club operations, lead meetings, and represent the club within the Hertie community and beyond.\nVice President: Assist the President and assume their duties in their absence, coordinate club activities, and manage subcommittees.\nSecretary: Maintain club records, meeting minutes, and membership information; schedule meetings and notify members of upcoming events.\nTreasurer: Manage club finances, including budgeting, fundraising, and allocation of resources.\nCommunications Officer: Oversee club communications, promote events and activities, and maintain the club’s online presence."
  },
  {
    "objectID": "members/statute/statute.html#section-3-elections",
    "href": "members/statute/statute.html#section-3-elections",
    "title": "Hertie Coding Club Statutes",
    "section": "Section 3: Elections",
    "text": "Section 3: Elections\nElections shall be held annually during the last meeting of the academic year. All club members are eligible to run for a position and vote in the election. The candidate receiving the most votes for each position shall be elected."
  },
  {
    "objectID": "members/statute/statute.html#section-1-frequency",
    "href": "members/statute/statute.html#section-1-frequency",
    "title": "Hertie Coding Club Statutes",
    "section": "Section 1: Frequency",
    "text": "Section 1: Frequency\nRegular club meetings shall be held weekly during the academic year. Additional meetings, workshops, or events may be scheduled as needed."
  },
  {
    "objectID": "members/statute/statute.html#section-2-quorum",
    "href": "members/statute/statute.html#section-2-quorum",
    "title": "Hertie Coding Club Statutes",
    "section": "Section 2: Quorum",
    "text": "Section 2: Quorum\nA quorum shall consist of at least 50% of the club’s active membership. Decisions shall be made by a majority vote of members present at a meeting with a quorum."
  },
  {
    "objectID": "members/statute/statute.html#section-1-budget",
    "href": "members/statute/statute.html#section-1-budget",
    "title": "Hertie Coding Club Statutes",
    "section": "Section 1: Budget",
    "text": "Section 1: Budget\nThe Treasurer shall prepare an annual budget for the club, detailing anticipated revenues and expenses for the academic year. The budget shall be approved by the Executive Committee and presented to the club membership for review."
  },
  {
    "objectID": "members/statute/statute.html#section-2-fundraising",
    "href": "members/statute/statute.html#section-2-fundraising",
    "title": "Hertie Coding Club Statutes",
    "section": "Section 2: Fundraising",
    "text": "Section 2: Fundraising\nThe club may engage in fundraising activities to support its operations and initiatives. All fundraising activities shall be conducted in accordance with applicable laws, regulations, and Hertie community guidelines."
  },
  {
    "objectID": "members/statute/statute.html#section-3-financial-reporting",
    "href": "members/statute/statute.html#section-3-financial-reporting",
    "title": "Hertie Coding Club Statutes",
    "section": "Section 3: Financial Reporting",
    "text": "Section 3: Financial Reporting\nThe Treasurer shall provide regular financial reports to the Executive Committee and club membership, detailing the club’s financial status and transactions."
  },
  {
    "objectID": "members/team/team.html",
    "href": "members/team/team.html",
    "title": "Team",
    "section": "",
    "text": "Academic Advisors\n\n\n\nAcademic Advisors\n\n\n\n\n\n\n\n\n\n\n\nInstructors\n\n\n\nInstructors\n\n\n\n\n\n      \n\n\n    \n\n        \n        \n        \n           Jorge Roa\n        \n        \n        \n        \n        \n           Lukas Warode \n        \n        \n        \n        \n        \n           Carmen Garro\n        \n        \n        \n        \n        \n           Rodrigo Dornelles\n        \n        \n        \n        \n        \n          Gabriel Zech\n        \n        \n        \n        \n        \n          Lukas Lehmann"
  },
  {
    "objectID": "members/team/team/gabriel_zech/gabrielzech.html",
    "href": "members/team/team/gabriel_zech/gabrielzech.html",
    "title": "Gabriel Zech",
    "section": "",
    "text": "I have been working as a project manager in the field of data science for public policy research since 2019. Having helped set up a Data Science Lab at the Bertelsmann Stiftung, I am particularly interested in how to systematically develop an organisation’s infrastructure, governance and culture in the field of data science. Going forward I want to further focus on working at the intersection between management and technical teams."
  },
  {
    "objectID": "members/team/team/lukas_warode/lukaswarode.html",
    "href": "members/team/team/lukas_warode/lukaswarode.html",
    "title": "Lukas Warode",
    "section": "",
    "text": "I’m part of the first MDS (2023) cohort, interested in data-driven approaches within the realm of social science and politics. Having a background in political science, I’m located somewhere in the intersection of political research and data science. With the experience of my past research positions, I’m currently working as a data research working student at POLITICO, where I assist the development of an analytical infrastructure."
  },
  {
    "objectID": "members/team/team/rodrigo_dornelles/rodrigodornelles.html",
    "href": "members/team/team/rodrigo_dornelles/rodrigodornelles.html",
    "title": "Rodrigo Dornelles",
    "section": "",
    "text": "Initially a lawyer with experience in criminal law, strategic litigation, and public law, I’ve now developed a strong passion for harnessing data analysis and data science to serve the public good. My diverse roles have included Research Assistant at the Hertie School Data Science Lab, Visiting Scholar at UC Berkeley, Attorney at Conectas Human Rights, and Chief Advisor at the Penitentiary Administration in Maranhão, Brazil.\nMy multidisciplinary background in law, public policy, and public management drives me to address complex social challenges such as public security, access to justice, and enhancing government effectiveness. I’m particularly fascinated with natural language processing (NLP), data wrangling, and web scraping as they enable me to extract valuable insights from intricate data sources. I’m always eager to collaborate with like-minded professionals to create innovative solutions that leave a lasting, positive impact on communities worldwide, with a special focus on Latin America."
  },
  {
    "objectID": "members/team/team/lukas_lehmann/lukaslehmann.html",
    "href": "members/team/team/lukas_lehmann/lukaslehmann.html",
    "title": "Lukas Lehmann",
    "section": "",
    "text": "Lukas is a first-year MIA student from the United States concentrating in International Security. He is particularly interested in corruption and how civil society organizations impact democratization around the world. Before coming to the Hertie School, he worked as a media analyst in Washington, D.C., where he leveraged his self-taught data analysis skills in the R programming language."
  },
  {
    "objectID": "members/team/team/jorge_roa/jorgeroa.html",
    "href": "members/team/team/jorge_roa/jorgeroa.html",
    "title": "Jorge Roa",
    "section": "",
    "text": "Hello! I’m Jorge! I have a background in public policy and a passion for using data to inform decision-making. My interests include:\n\nData Science for Public Policy: I’m currently pursuing a Master’s degree in Data Science for Public Policy at Hertie School in Berlin, Germany. I believe that data science can be a powerful tool for addressing complex public policy challenges, and I’m excited to continue exploring this field.\nTeaching and Education: I’m passionate about teaching. I’ve worked as a teaching assistant for courses on quantitative methods and public policy evaluation. I’m also the founder of the Hertie Coding Club, a space where students can learn programming skills for data analysis, wrangling and public policy."
  },
  {
    "objectID": "members/team/team/carmen_garro/carmengarro.html",
    "href": "members/team/team/carmen_garro/carmengarro.html",
    "title": "Carmen Garro",
    "section": "",
    "text": "I am Carmen, from Costa Rica. I did my undergrad in Statistics. I have worked in the internacional organization and public sectors. My intereses are in evidence made decision making, specially in public policy formulation."
  },
  {
    "objectID": "members/members/members.html",
    "href": "members/members/members.html",
    "title": "Members",
    "section": "",
    "text": "Members\n\n\n\nMembers"
  },
  {
    "objectID": "events/02_wrangle/index.html",
    "href": "events/02_wrangle/index.html",
    "title": "Meet Up III: Wrangle dataframes",
    "section": "",
    "text": "📍 Hertie School. Seminar Room 2.61\n🗓 November 18, 2022\n\nObjective: We will go over the fundamentals of data wrangling in R. We will create our first repo with GitHub and understand why using Git is important in the Data Science world. Also, we will move on to exploring methods for cleaning, transforming, and manipulating data using the dplyr package. We’ll discuss data operations like filtering, sorting, joining, and summing up. Participants will leave the session with a firm grasp on the fundamentals of data manipulation in R, which will serve as a solid foundation for further exploration and experimentation with this potent language."
  },
  {
    "objectID": "events/03_wrangle_part2/index.html",
    "href": "events/03_wrangle_part2/index.html",
    "title": "Meet Up III: Wrangle dataframes",
    "section": "",
    "text": "📍 Hertie School. Seminar Room 2.61\n🗓 14:00 - 16:00 hrs, November 24, 2022\n\nObjective: We will go over the fundamentals of data wrangling in R. We will continue exploring methods for cleaning, transforming, and manipulating data using the dplyr package. We’ll discuss data operations like filtering, sorting, joining, and summing up. Participants will leave the session with a firm grasp on the fundamentals of data manipulation in R, which will serve as a solid foundation for further exploration and experimentation with this potent language."
  },
  {
    "objectID": "events/05_social_media_analysis/index.html",
    "href": "events/05_social_media_analysis/index.html",
    "title": "Social Media Scraping",
    "section": "",
    "text": "📍 Hertie School. Seminar Room 1.61\n🗓 14:00 hrs, March 17, 2023\n\nObjective: An introduction to social media analysis! We’ll be scraping tweets from Twitter using the rtweet package, cleaning data, and using it to produce a variety of insightful visualizations. This session will provide you with some of the skills necessary to do social media research on your own, whether for a class, internship, or personal interest."
  },
  {
    "objectID": "events/01_kickoff_event/index.html",
    "href": "events/01_kickoff_event/index.html",
    "title": "Kick-Off Event: Hertie Coding Club",
    "section": "",
    "text": "📍 Hertie School. Forum\n🗓 November 04, 2022\n\nObjective: Our club’s goal is to assist you in developing the coding and programming skills you’ll need for your upcoming job, project, or academic inquiry. We are so excited to invite you to our presentation! We’ll discuss our club’s goals and the dates of our upcoming meetings during this session. You’ll also learn about our use of GitHub and Slack, two tools that are necessary for any coding project. We are so excited to meet you at our presentation and start this exciting new journey. Everyone can learn to code, keep that in mind!"
  },
  {
    "objectID": "events/04_environment/index.html",
    "href": "events/04_environment/index.html",
    "title": "Setting up your environment in Python",
    "section": "",
    "text": "📍 Hertie School. Seminar Room 2.34\n🗓 13:00 hrs, February 24, 2023\n\nObjective: The main learning outcome is for you to know how to set up reproducible and shareable environments for Python projects, understand how to effectively switch between environments when using an IDE and how to work more efficiently with IDEs, including how to use jupyter code cells within a .py script (a personal favourite of mine). The workshop will focus on Pipenv (the environment and packaging tool officially recommended by the Python developer community) and VSCode (a very customizable and efficient IDE). Nevertheless, the ideas and workflows covered here also apply for other tools (like Anaconda or venv, Sypder or Pycharm)."
  },
  {
    "objectID": "learn.html",
    "href": "learn.html",
    "title": "Learn",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "material/Resources/kaggle/index.html",
    "href": "material/Resources/kaggle/index.html",
    "title": "Kaggle",
    "section": "",
    "text": "If you want to play with multiple datasets, practice code, machine learning, enter competitions, among others, then Kaggle is your platform.\n\nKaggle is a web-based community platform for data scientists, machine learning engineers, and other data enthusiasts to share datasets, collaborate on data science projects, and participate in machine learning competitions.\nThe platform hosts a variety of data science challenges and competitions, ranging from predicting the outcome of sports events to detecting fraudulent transactions in financial data. The challenges are sponsored by companies and organizations that provide the datasets and offer prizes for the best performing models.\nKaggle offers access to datasets, code notebooks, forums for discussion, and online courses. Kaggle has become a popular platform for data science enthusiasts and professionals alike, and has contributed to the growth and development of the data science community by providing a platform for collaboration, learning, and competition.\n\n\n\n\n\nGo to Kaggle"
  },
  {
    "objectID": "material/Resources/indexp.html",
    "href": "material/Resources/indexp.html",
    "title": "Resources",
    "section": "",
    "text": "These tools offer a wealth of learning opportunities, including interactive courses, real-world projects, and community forums where you can connect with other learners."
  },
  {
    "objectID": "material/Resources/indexp.html#resources",
    "href": "material/Resources/indexp.html#resources",
    "title": "Resources",
    "section": "Resources",
    "text": "Resources\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nedX\n\n\nedX offers varios online courses with free verified certificates\n\n\n\nApr 5, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKaggle\n\n\nInside Kaggle you’ll find all the code & data you need to do your data science work.\n\n\n\nMar 30, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDataquest Premium Access\n\n\nDataquest is platform that offers coding challenges and projects to learn essential data science skillsets.\n\n\n\nMar 29, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "material/Resources/edx/index.html",
    "href": "material/Resources/edx/index.html",
    "title": "edX",
    "section": "",
    "text": "edX is an amazing tool to practice code, but also to earn certificates. edX is a non-profit online learning platform that was founded by Harvard University and MIT in 2012. According to their history, it has partnered with universities, organizations, and institutions globally to create a network of educational resources. edX offers paid courses with the option to earn a certificate or credential upon completion; however, you can take the entire course without the certification and start building your portfolio. Check all the courses, the ones that I recommend are teach it by Harvard professors.\n\n\n\n\nGo to edX\n\n\n\n\n\n\n\n\n\nCite\n\n\n\n\n\nRoa, J. (2023, April 5). EdX. Hertie Coding Club. URL"
  },
  {
    "objectID": "material/Resources/dataquest/index.html",
    "href": "material/Resources/dataquest/index.html",
    "title": "Dataquest Premium Access",
    "section": "",
    "text": "“Dataquest is a self-learning platform that offers interactive coding challenges and projects to learn essential data science skillsets. Four distinct paths can be chosen with different learning materials: Data Analyst in R, Data Analyst in Python, Data Scientist in Python, or Data Engineer. By completing the learning paths, students will receive certificates and create projects that can be added to their data science portfolio as a demonstration of their skills to potential employers. In order to get access to premium Dataquest account for Fall semester 2021, please contact the Data Science Lab team at datasciencelab@hertie-school.org. The start of every learning path is always focused on building up the foundation of the programming language. Therefore, if you are looking for a place to start, step 1 in Data Analyst or Data Scientist tracks for both R and Python concerns with developing your programming skills from beginner to intermediate level.”\n\nData science training resources\n\n\n\n\nGo to Dataquest"
  },
  {
    "objectID": "material/Books/art_ds/index.html",
    "href": "material/Books/art_ds/index.html",
    "title": "The Art of Data Science: A Guide for Anyone Who Works with Data",
    "section": "",
    "text": "Author Roger D. Peng Elizabeth Matsui\n\n\nMore than a book, this is a guide to follow in the general data science processes. It’s totally worth it because it gives you a series of steps to start from the scratch to answer a research question or a hypothesis.\n“What we have set out to do in this book is to write down the process of data analysis. What we describe is not a specific “formula” for data analysis—something like “apply this method and then run that test”— but rather is a general process that can be applied in a variety of situations. Through our extensive experience both managing data analysts and conducting our own data analyses, we have carefully observed what produces coherent results and what fails to produce useful insights into data. Our goal is to write down what we have learned in the hopes that others may find it useful.”\n\n\n\nGo to Art of Data Science\n\n\n\n\n\n\n\n\n\n\nCite\n\n\n\nPeng, R. D., & Matsui, E. (2016). The Art of Data Science: A guide for anyone who works with Data. (No Title)."
  },
  {
    "objectID": "material/Books/python_for_ev/index.html",
    "href": "material/Books/python_for_ev/index.html",
    "title": "Python for Everybody",
    "section": "",
    "text": "Author Charles Severance\n\n\nProbably Charles Severance is one of the most famous people that teaches Python. In his book, he covers multiple topics in an approachable way. Also, one of the advantages of this material is that he offers free materials, lectures, and even certificates from edX and freecodecamp. Python is by far the most popular programming language in the world, and this course is an excellent opportunity to start learning this skill.\n“Python for Everybody is an introduction to the basics of coding in Python 3 with an emphasis on practical usage. It is intended as a foundation for students who are looking to apply Python within other academic subjects as well as in preparation for the serious study of computer science.”\n\n\n\nLectures\n\n\n\n\nChapter 1: Introduction\n\n\nChapter 2: Variables\n\n\nChapter 3: Conditionals\n\n\nChapter 4: Functions\n\n\nChapter 5: Iterations\n\n\nChapter 6: Strings\n\n\nChapter 7: Files\n\n\nChapter 8: Lists\n\n\nChapter 9: Dictionaries\n\n\nChapter 10: Tuples\n\n\nChapter 11: Regex\n\n\nChapter 12: Networked Programs\n\n\nChapter 13: Python and Web Services\n\n\nChapter 14: Objects\n\n\nChapter 15: Python and Databases\n\n\n\n\n\n\nGo to Python for everybody\n\n\n\n\n\n\nGo to website PFE\n\n\n\n\n\n\n\n\n\n\nCite\n\n\n\nSeverance, C. R. (2020). Python for everybody. Charles Severance."
  },
  {
    "objectID": "material/Books/data_management/index.html",
    "href": "material/Books/data_management/index.html",
    "title": "Data Management for Social Scientists: From Files to Databases",
    "section": "",
    "text": "Author Nils B. Weidmann\n\n\nData management knowledge is critical for understanding the data that we want to handle. This excellent book provides a broad approach to why data management is essential. Also, it offers us all the chapters and exercises in a repo to replicate them.\n“The ‘data revolution’ offers many new opportunities for research in the social sciences. Increasingly, social and political interactions can be recorded digitally, leading to vast amounts of new data available for research. This poses new challenges for organizing and processing research data. This comprehensive introduction covers the entire range of data management techniques, from flat files to database management systems. It demonstrates how established techniques and technologies from computer science can be applied in social science projects, drawing on a wide range of different applied examples. This book covers simple tools such as spreadsheets and file-based data storage and processing, as well as more powerful data management software like relational databases. It goes on to address advanced topics such as spatial data, text as data, and network data. This book is one of the first to discuss questions of practical data management specifically for social science projects.”\n\n\n\nGo to Data Management\n\n\n\n\n\n\nGo to Repo of the book\n\n\n\n\n\n\n\n\n\n\nCite\n\n\n\nWeidmann, N. (2023). Data Management for Social Scientists: From Files to Databases (Methodological Tools in the Social Sciences). Cambridge: Cambridge University Press. doi:10.1017/9781108990424"
  },
  {
    "objectID": "material/Books/ggplot2/index.html",
    "href": "material/Books/ggplot2/index.html",
    "title": "ggplot2: elegant graphics for data analysis",
    "section": "",
    "text": "Author Hadley Wickham\n\n\nThis book is one of the classics when we discuss about data visualization. ggplot documentation is proper; however, understanding ggplot applied to real cases is by far more critical. In this case, ggplot2 helps us learn the core of how ggplot2 works and how we can get the best advantage of it.\n“This book provides a hands-on introduction to ggplot2 with lots of example code and graphics. It also explains the grammar on which ggplot2 is based. Like other formal systems, ggplot2 is useful even when you don’t understand the underlying model. However, the more you learn about it, the more effectively you’ll be able to use ggplot2. This book will introduce you to ggplot2 assuming that you’re a novice, unfamiliar with the grammar; teach you the basics so that you can re-create plots you are already familiar with; show you how to use the grammar to create new types of graphics; and eventually turn you into an expert who can build new components to extend the grammar.”\n\n\n\nGo to ggplot2\n\n\n\n\n\n\n\n\n\n\nCite\n\n\n\nHadley, W. (2016). ggplot2: elegant graphics for data analysis. Hadley Wickham."
  },
  {
    "objectID": "material/Books/ids_r/index.html",
    "href": "material/Books/ids_r/index.html",
    "title": "Introduction to Data Science",
    "section": "",
    "text": "Author Rafael A Irizarry\n\n\nIf you don’t have any experience with R, this is an excellent way to start. Rafael’s explanation of R is friendly and provocative to keep the lector engaged. Certainly, it covers all the core topics and skills that a data scientist must have.\n“This book is meant to be a textbook for a first course in Data Science. No previous knowledge of R is necessary, although some experience with programming may be helpful. The statistical concepts used to answer the case study questions are only briefly introduced, so a Probability and Statistics textbook is highly recommended for in-depth understanding of these concepts. If you read and understand all the chapters and complete all the exercises, you will be well-positioned to perform basic data analysis tasks and you will be prepared to learn the more advanced concepts and skills needed to become an expert.”\n\n\n\n\n\n\nLectures\n\n\n\n\nPart 1: Basics of R and the tidyverse\n\n\nLearn R throughout the book\n\n\nBuilding blocks needed to keep learning\n\n\nPart 2: Data visualization with ggplot2\n\n\nUse ggplot2 to generate graphs\n\n\nDescribe important data visualization principles\n\n\nPart 3: Statistics with R\n\n\nAnswer case study questions using probability, inference, and regression\n\n\nDemonstrate the importance of statistics in data analysis\n\n\nPart 4: Data wrangling with tidyverse\n\n\nFamiliarize the reader with data wrangling\n\n\nSpecific skills include web scraping, using regular expressions, and joining and reshaping data tables\n\n\nPart 5: Machine learning with caret\n\n\nIntroduce machine learning through challenges\n\n\nUse the caret package to build prediction algorithms including K-nearest neighbors and random forests\n\n\nPart 6: Productivity tools for data science\n\n\nBrief introduction to productivity tools used in data science projects\n\n\nTools include RStudio, UNIX/Linux shell, Git and GitHub, and knitr and R Markdown.\n\n\n\n\n\n\nGo to Intro to Data Science\n\n\n\n\n\n\n\n\n\n\nCite\n\n\n\nIrizarry, R. A. (2019). Introduction to data science: Data analysis and prediction algorithms with R. CRC Press."
  },
  {
    "objectID": "material/Books/indexp.html",
    "href": "material/Books/indexp.html",
    "title": "Books",
    "section": "",
    "text": "Discover some useful books on coding and other relevant topics. Happy reading!"
  },
  {
    "objectID": "material/Books/indexp.html#books",
    "href": "material/Books/indexp.html#books",
    "title": "Books",
    "section": "Books",
    "text": "Books\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nData Management for Social Scientists: From Files to Databases\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Art of Data Science: A Guide for Anyone Who Works with Data\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploratory Data Analysis with R\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpatial Data Science with applications in R\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot2: elegant graphics for data analysis\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to Data Science\n\n\n\n\n\n\n\n\n\n\n\n\n\nPython for Everybody\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeb Scraping with R\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Visualization: A Practical Introduction\n\n\n\n\n\n\n\n\n\n\n\n\n\nR for Data Science\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "material/Books/eda_r/index.html",
    "href": "material/Books/eda_r/index.html",
    "title": "Exploratory Data Analysis with R",
    "section": "",
    "text": "Authors Roger D. Peng\n\n\nExploratory Data Analysis (EDA) is the core skill that a Data Analyst must have. This book provides the most useful function of the tidyverse and structures how to do a data analysis in the most efficient way. Happy reading!\n“This book covers the essential exploratory techniques for summarizing data with R. These techniques are typically applied before formal modeling commences and can help inform the development of more complex statistical models. Exploratory techniques are also important for eliminating or sharpening potential hypotheses about the world that can be addressed by the data you have. We will cover in detail the plotting systems in R as well as some of the basic principles of constructing informative data graphics. We will also cover some of the common multivariate statistical techniques used to visualize high-dimensional data.”\n\n\n\nGo to Exploratory Data Analysis with R\n\n\n\n\n\n\n\n\n\n\nCite\n\n\n\nPeng, R. D. (2020, May 1). Exploratory data analysis with R. Bookdown. URL"
  },
  {
    "objectID": "material/Books/webscrapping_r/index.html",
    "href": "material/Books/webscrapping_r/index.html",
    "title": "Web Scraping with R",
    "section": "",
    "text": "Author Steve Pittard\n\n\nThis book has recent material and methods to learn web scraping with R using the tidyverse. It has a modern approach to getting different data types from the web and introduces API which is one fantastic option to retrieve data. I also like that it contains an example using the web scraped data doing sentiment analysis. Happy reading!\n“Web Scraping with R” is a comprehensive guide that provides readers with a practical and comprehensive introduction to web scraping using the R programming language. The book covers a wide range of topics related to web scraping, from the motivation for web scraping, to the techniques and tools used for web scraping, as well as the challenges that come with the process. The book is divided into several chapters, each of which delves into a particular aspect of web scraping using R.”\n\n\n\nGo to Webscraping for R\n\n\n\n\n\n\n\n\n\n\nCite\n\n\n\nPittard, S. (2022, February 8). Web scraping with R. Carousel Template for Bootstrap. URL"
  },
  {
    "objectID": "material/Books/r_for_ds/index.html",
    "href": "material/Books/r_for_ds/index.html",
    "title": "R for Data Science",
    "section": "",
    "text": "Author Hadley Wickham Garrett Grolemund\n\n\nThis book is a great way to start in the data science world. When I took my Introduction to Data Science course, this book was the one that we used. It gives you a clear structure, good practices for coding, and all the basis that you need. —100% recommended.\n“R4DS teaches you how to do data science with R: You’ll learn how to get your data into R, get it into the most useful structure, transform it, visualise it and model it. In this book, you will find a practicum of skills for data science. Just as a chemist learns how to clean test tubes and stock a lab, you’ll learn how to clean data and draw plots—and many other things besides. These are the skills that allow data science to happen, and here you will find the best practices for doing each of these things with R. You’ll learn how to use the grammar of graphics, literate programming, and reproducible research to save time. You’ll also learn how to manage cognitive resources to facilitate discoveries when wrangling, visualising, and exploring data.”\n\n\n\nGo to R for Data Science\n\n\n\n\n\n\n\n\n\n\nCite\n\n\n\nWickham, H., & Grolemund, G. (2016). R for data science: import, tidy, transform, visualize, and model data. ” O’Reilly Media, Inc.”."
  },
  {
    "objectID": "material/Books/data_vis/index.html",
    "href": "material/Books/data_vis/index.html",
    "title": "Data Visualization: A Practical Introduction",
    "section": "",
    "text": "Author Kieran Healy\n\n\nWhat I like about this book is that it gives you exercises, practice code, and the theory behind visualization and storytelling. Kieran Healy provides fantastic examples of plots and makes you understand the critical concepts behind ggplot. If you want to have a solid theoretical basis for plots and practical examples, this is your bible now.\n“This book is a hands-on introduction to the principles and practice of looking at and presenting data using R and ggplot. R is a powerful, widely used, and freely available programming language for data analysis. You may be interested in exploring ggplot after having used R before, or be entirely new to both R and ggplot and just want to graph your data. I do not assume you have any prior knowledge of R.”\nIf you follow the text and examples in this book, then by the end you will:\n\nUnderstand the basic principles behind effective data visualization.\nHave a practical sense for why some graphs and figures work well, while others may fail to inform or actively mislead.\nKnow how to create a wide range of plots in R using ggplot2.\nKnow how to refine plots for effective presentation.\n\n\n\n\nGo to Data Visualization\n\n\n\n\n\n\n\n\n\n\nCite\n\n\n\nHealy, K. (2018). Data visualization: a practical introduction. Princeton University Press."
  },
  {
    "objectID": "material/Books/spatial_ds/index.html",
    "href": "material/Books/spatial_ds/index.html",
    "title": "Spatial Data Science with applications in R",
    "section": "",
    "text": "Authors Edzer Pebesma Roger Bivand\n\n\nOne of the things that I like about R is how flexible it is as a tool or a “swiss knife” because you can employ different tools that before weren’t possible. One of them is Spatial Analysis and this book provides a robust theoretical and practical background using R for Spatial analysis. It’s updated and delivers clear examples of how spatial data is super useful for data analysis and other purposes.\n“This book introduces and explains the concepts underlying spatial data: points, lines, polygons, rasters, coverages, geometry attributes, data cubes, reference systems, as well as higher-level concepts including how attributes relate to geometries and how this affects analysis. The relationship of attributes to geometries is known as support, and changing support also changes the characteristics of attributes. Some data generation processes are continuous in space, and may be observed everywhere. Others are discrete, observed in tesselated containers. In modern spatial data analysis, tesellated methods are often used for all data, extending across the legacy partition into point process, geostatistical and lattice models. It is support (and the understanding of support) that underlies the importance of spatial representation. The book aims at data scientists who want to get a grip on using spatial data in their analysis. To exemplify how to do things, it uses R”\n\n\n\nGo to Spatial Data Science\n\n\n\n\n\n\n\n\n\n\nCite\n\n\n\nPebesma, E., & Bivand, R. (2023). Spatial Data Science: With Applications in R. CRC Press."
  },
  {
    "objectID": "material/index.html",
    "href": "material/index.html",
    "title": "Material",
    "section": "",
    "text": "Material\nHere you can find material that covers books, free certifications, projects for your portfolio and some helpful resources to start or sharp your coding skills.\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\nBooks\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nCertifications\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nResources\n\n\n\n\n\n\n\n \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "material/Certifications/indexp.html",
    "href": "material/Certifications/indexp.html",
    "title": "Certifications",
    "section": "",
    "text": "These free certifications cover a range of coding languages and technologies, and can help you demonstrate your expertise to potential employers."
  },
  {
    "objectID": "material/Certifications/indexp.html#certifications",
    "href": "material/Certifications/indexp.html#certifications",
    "title": "Certifications",
    "section": "Certifications",
    "text": "Certifications\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nCISCO Networking Academy\n\n\nPCAP: Programming Essentials in Python. Learn programming from scratch and master Python.\n\n\n\n\n\n\n\n\n\n\n\n\n\nfreeCodeCamp Certifications\n\n\nLearn to code — for free. Build projects. Earn certifications.\n\n\n\n\n\n\n\n\n\n\n\n\n\nIBM Data Analyst certification\n\n\nTry this course for free and get your certification by IBM in Data Analyst\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "material/Certifications/freecodecamp/index.html",
    "href": "material/Certifications/freecodecamp/index.html",
    "title": "freeCodeCamp Certifications",
    "section": "",
    "text": "freeCodeCamp is a platform that offers free, self-paced, interactive online courses in various areas of computer science, including web development, data science, data analysis, and machine learning. I’ve used it a couple of times and it’s incredible powerful. It can be used by beginners and advanced students, the curriculum includes hands-on projects that help students build practical skills and portfolios. The organization aims to provide accessible, high-quality education to anyone interested in programming.\n\nThis platform is completely free and is a good option if you want to practice and learn different skills.\n\n\n\n\nGo to freeCodeCamp"
  },
  {
    "objectID": "material/Certifications/IBM_data_analyst/index.html",
    "href": "material/Certifications/IBM_data_analyst/index.html",
    "title": "IBM Data Analyst certification",
    "section": "",
    "text": "“To thrive, companies must leverage data to understand trends, predict outcomes, and innovate. Data analysts are instrumental to helping companies achieve this. Try this course for free and get your certification by IBM in Data Analyst. IBM offers a comprehensive, free Data Analyst course designed for learners to gain essential data analysis skills and industry-recognized credentials. The course covers data science methodologies, data analysis and visualization using Python, common data science tools, and libraries. By the end of the course, students will be able to apply their newly acquired skills to a final project and report. With a growing demand for data analysts, this course provides an excellent opportunity for learners to join the thriving data sector and showcase their expertise with digital credentials from IBM.”\n\nThis certification is completely free and is a good option if you want to start learning the tools that a Data analyst must have.\n\n\n\n\nGo to the course"
  },
  {
    "objectID": "material/Certifications/cisco_pcap/index.html",
    "href": "material/Certifications/cisco_pcap/index.html",
    "title": "CISCO Networking Academy",
    "section": "",
    "text": "This is a course offered by the CISCO Networking Academy. What I really like is that at the end it offers a proof of completion. This certification in combination with other tools it’s a good way to start with Python. Here I leave the summary of the CISCO website and the link as well.\n\n“How great would it be to write your own computer program? Python is a multi-paradigm programming language used by startups and tech giants like Google, Facebook, Netflix, and more. With intuitive, readable syntax, Python is a great first programming language to learn.\nProgramming skills open you up to careers in almost any industry and are required if you want to continue to more advanced and higher paying software development and engineering roles.\nThis course is a great place to start learning Python – no prior programming knowledge required. Completing the course earns you a Statement of Achievement. It is split into two parts preparing you for two certifications:\nPart 1 (PE1: 35 hours) prepares you for PCEP – Certified Entry-Level Python Programmer Certification. Part 2 (PE2: 40 hours) prepares you for PCAP – Certified Associate in Python Programming Certification.”\nYou’ll learn these core skills:\n\nThink algorithmically – how to analyze a problem and translate it for a computer to process.\nDesign, develop, and improve multi-module computer programs.\nAnalyze and model real-life problems in Object-Oriented Programming categories.\nUnderstand a programmer’s work in the software development process.\nLearn how a program is executed in a computer environment.\nGain skills to create and develop your own programming portfolio.\n\n\nCISCO Networking Academy\n\n\n\n\nGo to CISCO PCAP"
  }
]